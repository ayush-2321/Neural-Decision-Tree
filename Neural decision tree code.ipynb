{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e272aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8b376d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74af96e4",
   "metadata": {},
   "source": [
    "### Trying Simple 1 depth neural decision Tree for a Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f536c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(-10,10)\n",
    "y=[]\n",
    "for i in range(x.shape[0]):\n",
    "    if(x[i]<5):\n",
    "        y.append(0)\n",
    "    else:\n",
    "        y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d64a7cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(y)\n",
    "y=y.astype(\"float32\")\n",
    "y=torch.tensor(y)\n",
    "x=x.astype(\"float32\")\n",
    "x=torch.tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "744b1ed4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-10.,  -9.,  -8.,  -7.,  -6.,  -5.,  -4.,  -3.,  -2.,  -1.,   0.,   1.,\n",
       "          2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bc4501d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "        1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bedbaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nntree(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.t1=nn.Parameter(torch.randn(1))\n",
    "        self.b1=nn.Parameter(torch.randn(1))\n",
    "        self.relu=nn.ReLU()\n",
    "        self.softmax=nn.Softmax()\n",
    "    def forward(self,x):\n",
    "        x=self.t1*x+self.b1\n",
    "        x1=self.relu(x)\n",
    "        x2=self.relu(-x)\n",
    "        x=torch.cat((x1,x2),0)\n",
    "        x=self.softmax(x)\n",
    "        return x\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dc10cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=nntree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaf40128",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.BCELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c047af33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srika\\AppData\\Local\\Temp\\ipykernel_5336\\2928045597.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x=self.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.1764, grad_fn=<AddBackward0>)\n",
      "tensor(10.9031, grad_fn=<AddBackward0>)\n",
      "tensor(9.6637, grad_fn=<AddBackward0>)\n",
      "tensor(8.4666, grad_fn=<AddBackward0>)\n",
      "tensor(7.3225, grad_fn=<AddBackward0>)\n",
      "tensor(6.2459, grad_fn=<AddBackward0>)\n",
      "tensor(5.2563, grad_fn=<AddBackward0>)\n",
      "tensor(4.3804, grad_fn=<AddBackward0>)\n",
      "tensor(3.6538, grad_fn=<AddBackward0>)\n",
      "tensor(3.1232, grad_fn=<AddBackward0>)\n",
      "tensor(2.8415, grad_fn=<AddBackward0>)\n",
      "tensor(2.8472, grad_fn=<AddBackward0>)\n",
      "tensor(3.1108, grad_fn=<AddBackward0>)\n",
      "tensor(3.4832, grad_fn=<AddBackward0>)\n",
      "tensor(3.7552, grad_fn=<AddBackward0>)\n",
      "tensor(3.8063, grad_fn=<AddBackward0>)\n",
      "tensor(3.6478, grad_fn=<AddBackward0>)\n",
      "tensor(3.3638, grad_fn=<AddBackward0>)\n",
      "tensor(3.0486, grad_fn=<AddBackward0>)\n",
      "tensor(2.7726, grad_fn=<AddBackward0>)\n",
      "tensor(2.5719, grad_fn=<AddBackward0>)\n",
      "tensor(2.4523, grad_fn=<AddBackward0>)\n",
      "tensor(2.4012, grad_fn=<AddBackward0>)\n",
      "tensor(2.3975, grad_fn=<AddBackward0>)\n",
      "tensor(2.4198, grad_fn=<AddBackward0>)\n",
      "tensor(2.4500, grad_fn=<AddBackward0>)\n",
      "tensor(2.4747, grad_fn=<AddBackward0>)\n",
      "tensor(2.4854, grad_fn=<AddBackward0>)\n",
      "tensor(2.4779, grad_fn=<AddBackward0>)\n",
      "tensor(2.4513, grad_fn=<AddBackward0>)\n",
      "tensor(2.4079, grad_fn=<AddBackward0>)\n",
      "tensor(2.3514, grad_fn=<AddBackward0>)\n",
      "tensor(2.2869, grad_fn=<AddBackward0>)\n",
      "tensor(2.2200, grad_fn=<AddBackward0>)\n",
      "tensor(2.1562, grad_fn=<AddBackward0>)\n",
      "tensor(2.1002, grad_fn=<AddBackward0>)\n",
      "tensor(2.0553, grad_fn=<AddBackward0>)\n",
      "tensor(2.0231, grad_fn=<AddBackward0>)\n",
      "tensor(2.0030, grad_fn=<AddBackward0>)\n",
      "tensor(1.9925, grad_fn=<AddBackward0>)\n",
      "tensor(1.9880, grad_fn=<AddBackward0>)\n",
      "tensor(1.9849, grad_fn=<AddBackward0>)\n",
      "tensor(1.9793, grad_fn=<AddBackward0>)\n",
      "tensor(1.9684, grad_fn=<AddBackward0>)\n",
      "tensor(1.9514, grad_fn=<AddBackward0>)\n",
      "tensor(1.9290, grad_fn=<AddBackward0>)\n",
      "tensor(1.9031, grad_fn=<AddBackward0>)\n",
      "tensor(1.8761, grad_fn=<AddBackward0>)\n",
      "tensor(1.8502, grad_fn=<AddBackward0>)\n",
      "tensor(1.8272, grad_fn=<AddBackward0>)\n",
      "tensor(1.8078, grad_fn=<AddBackward0>)\n",
      "tensor(1.7921, grad_fn=<AddBackward0>)\n",
      "tensor(1.7793, grad_fn=<AddBackward0>)\n",
      "tensor(1.7686, grad_fn=<AddBackward0>)\n",
      "tensor(1.7589, grad_fn=<AddBackward0>)\n",
      "tensor(1.7492, grad_fn=<AddBackward0>)\n",
      "tensor(1.7388, grad_fn=<AddBackward0>)\n",
      "tensor(1.7275, grad_fn=<AddBackward0>)\n",
      "tensor(1.7150, grad_fn=<AddBackward0>)\n",
      "tensor(1.7016, grad_fn=<AddBackward0>)\n",
      "tensor(1.6878, grad_fn=<AddBackward0>)\n",
      "tensor(1.6738, grad_fn=<AddBackward0>)\n",
      "tensor(1.6603, grad_fn=<AddBackward0>)\n",
      "tensor(1.6474, grad_fn=<AddBackward0>)\n",
      "tensor(1.6355, grad_fn=<AddBackward0>)\n",
      "tensor(1.6245, grad_fn=<AddBackward0>)\n",
      "tensor(1.6144, grad_fn=<AddBackward0>)\n",
      "tensor(1.6049, grad_fn=<AddBackward0>)\n",
      "tensor(1.5958, grad_fn=<AddBackward0>)\n",
      "tensor(1.5868, grad_fn=<AddBackward0>)\n",
      "tensor(1.5777, grad_fn=<AddBackward0>)\n",
      "tensor(1.5684, grad_fn=<AddBackward0>)\n",
      "tensor(1.5590, grad_fn=<AddBackward0>)\n",
      "tensor(1.5493, grad_fn=<AddBackward0>)\n",
      "tensor(1.5397, grad_fn=<AddBackward0>)\n",
      "tensor(1.5302, grad_fn=<AddBackward0>)\n",
      "tensor(1.5209, grad_fn=<AddBackward0>)\n",
      "tensor(1.5119, grad_fn=<AddBackward0>)\n",
      "tensor(1.5032, grad_fn=<AddBackward0>)\n",
      "tensor(1.4948, grad_fn=<AddBackward0>)\n",
      "tensor(1.4867, grad_fn=<AddBackward0>)\n",
      "tensor(1.4788, grad_fn=<AddBackward0>)\n",
      "tensor(1.4710, grad_fn=<AddBackward0>)\n",
      "tensor(1.4633, grad_fn=<AddBackward0>)\n",
      "tensor(1.4556, grad_fn=<AddBackward0>)\n",
      "tensor(1.4480, grad_fn=<AddBackward0>)\n",
      "tensor(1.4403, grad_fn=<AddBackward0>)\n",
      "tensor(1.4328, grad_fn=<AddBackward0>)\n",
      "tensor(1.4253, grad_fn=<AddBackward0>)\n",
      "tensor(1.4179, grad_fn=<AddBackward0>)\n",
      "tensor(1.4106, grad_fn=<AddBackward0>)\n",
      "tensor(1.4035, grad_fn=<AddBackward0>)\n",
      "tensor(1.3965, grad_fn=<AddBackward0>)\n",
      "tensor(1.3897, grad_fn=<AddBackward0>)\n",
      "tensor(1.3829, grad_fn=<AddBackward0>)\n",
      "tensor(1.3763, grad_fn=<AddBackward0>)\n",
      "tensor(1.3697, grad_fn=<AddBackward0>)\n",
      "tensor(1.3632, grad_fn=<AddBackward0>)\n",
      "tensor(1.3568, grad_fn=<AddBackward0>)\n",
      "tensor(1.3504, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "num_epochs=100\n",
    "epoch=0\n",
    "for epoch in range(num_epochs):\n",
    "    loss=0\n",
    "    for i in range(20):\n",
    "        output=model(x[i])\n",
    "        loss+=criterion(output[0],y[i])\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05ff9a28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.4833e-08, 1.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.1587e-07, 1.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([3.8545e-07, 1.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.2822e-06, 1.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([4.2653e-06, 1.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.4189e-05, 9.9999e-01], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([4.7197e-05, 9.9995e-01], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.5699e-04, 9.9984e-01], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([5.2203e-04, 9.9948e-01], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.0017, 0.9983], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.0057, 0.9943], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.0189, 0.9811], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.0601, 0.9399], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1754, 0.8246], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.4144, 0.5856], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.7019, 0.2981], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.8868, 0.1132], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.9630, 0.0370], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.9886, 0.0114], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.9965, 0.0035], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srika\\AppData\\Local\\Temp\\ipykernel_5336\\2928045597.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x=self.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(model(x[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1aba308f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 tensor([1.2019])\n",
      "b1 tensor([-5.1534])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a14d239",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-10.,  -9.,  -8.,  -7.,  -6.,  -5.,  -4.,  -3.,  -2.,  -1.,   0.,   1.,\n",
       "          2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ff33d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "        1., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928fed86",
   "metadata": {},
   "source": [
    "### Trying Depth 2 neural decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38e7b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(-10,10)\n",
    "y=[]\n",
    "for i in range(x.shape[0]):\n",
    "    if(x[i]<5 and x[i]>=0):\n",
    "        y.append(0)\n",
    "    else:\n",
    "        y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f51b2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(y)\n",
    "y=y.astype(\"float32\")\n",
    "y=torch.tensor(y)\n",
    "x=x.astype(\"float32\")\n",
    "x=torch.tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a2bf475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-10.,  -9.,  -8.,  -7.,  -6.,  -5.,  -4.,  -3.,  -2.,  -1.,   0.,   1.,\n",
       "          2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c899ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "        1., 1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c26ce670",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nntree2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.t1=nn.Parameter(torch.randn(1))\n",
    "        self.b1=nn.Parameter(torch.randn(1))\n",
    "        self.t11=nn.Parameter(torch.randn(1))\n",
    "        self.b11=nn.Parameter(torch.randn(1))\n",
    "        self.t12=nn.Parameter(torch.randn(1))\n",
    "        self.b12=nn.Parameter(torch.randn(1))\n",
    "        self.relu=nn.ReLU()\n",
    "        self.softmax=nn.Softmax()\n",
    "    def forward(self,x):\n",
    "        o=self.t1*x+self.b1\n",
    "        o1=torch.max(torch.tensor(0.01),self.relu(o))\n",
    "        o2=torch.max(torch.tensor(0.01),self.relu(-o))\n",
    "        o1=o1*(self.t11*x+self.b11)\n",
    "        o2=o2*(self.t12*x+self.b12)\n",
    "        o11=torch.max(torch.tensor(0.01),self.relu(o1))\n",
    "        o12=torch.max(torch.tensor(0.01),self.relu(-o1))\n",
    "        o21=torch.max(torch.tensor(0.01),self.relu(o2))\n",
    "        o22=torch.max(torch.tensor(0.01),self.relu(-o2))\n",
    "        p1=o11+o21\n",
    "        p2=o12+o22 \n",
    "        f=torch.cat((p1,p2),0)\n",
    "        f=self.softmax(f)\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "331ce43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=nntree2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ed0ae7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srika\\AppData\\Local\\Temp\\ipykernel_5336\\764618393.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  f=self.softmax(f)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.8939, 0.1061], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48523d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.BCELoss()\n",
    "optimizer=torch.optim.Adam(model1.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d8f4027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srika\\AppData\\Local\\Temp\\ipykernel_5336\\764618393.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  f=self.softmax(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.2552, grad_fn=<AddBackward0>)\n",
      "tensor(9.8159, grad_fn=<AddBackward0>)\n",
      "tensor(6.2856, grad_fn=<AddBackward0>)\n",
      "tensor(7.4188, grad_fn=<AddBackward0>)\n",
      "tensor(7.7036, grad_fn=<AddBackward0>)\n",
      "tensor(6.5024, grad_fn=<AddBackward0>)\n",
      "tensor(5.4434, grad_fn=<AddBackward0>)\n",
      "tensor(5.7863, grad_fn=<AddBackward0>)\n",
      "tensor(6.0278, grad_fn=<AddBackward0>)\n",
      "tensor(5.7707, grad_fn=<AddBackward0>)\n",
      "tensor(5.2183, grad_fn=<AddBackward0>)\n",
      "tensor(4.5802, grad_fn=<AddBackward0>)\n",
      "tensor(4.5240, grad_fn=<AddBackward0>)\n",
      "tensor(4.6353, grad_fn=<AddBackward0>)\n",
      "tensor(4.6050, grad_fn=<AddBackward0>)\n",
      "tensor(4.3632, grad_fn=<AddBackward0>)\n",
      "tensor(3.9742, grad_fn=<AddBackward0>)\n",
      "tensor(3.5631, grad_fn=<AddBackward0>)\n",
      "tensor(3.3477, grad_fn=<AddBackward0>)\n",
      "tensor(3.2812, grad_fn=<AddBackward0>)\n",
      "tensor(3.2187, grad_fn=<AddBackward0>)\n",
      "tensor(3.0448, grad_fn=<AddBackward0>)\n",
      "tensor(2.7629, grad_fn=<AddBackward0>)\n",
      "tensor(2.4681, grad_fn=<AddBackward0>)\n",
      "tensor(2.3159, grad_fn=<AddBackward0>)\n",
      "tensor(2.2418, grad_fn=<AddBackward0>)\n",
      "tensor(2.1356, grad_fn=<AddBackward0>)\n",
      "tensor(2.0095, grad_fn=<AddBackward0>)\n",
      "tensor(1.9215, grad_fn=<AddBackward0>)\n",
      "tensor(1.7944, grad_fn=<AddBackward0>)\n",
      "tensor(1.6917, grad_fn=<AddBackward0>)\n",
      "tensor(1.4565, grad_fn=<AddBackward0>)\n",
      "tensor(1.2862, grad_fn=<AddBackward0>)\n",
      "tensor(1.2623, grad_fn=<AddBackward0>)\n",
      "tensor(1.2799, grad_fn=<AddBackward0>)\n",
      "tensor(1.1937, grad_fn=<AddBackward0>)\n",
      "tensor(1.0321, grad_fn=<AddBackward0>)\n",
      "tensor(0.9269, grad_fn=<AddBackward0>)\n",
      "tensor(0.9142, grad_fn=<AddBackward0>)\n",
      "tensor(0.9106, grad_fn=<AddBackward0>)\n",
      "tensor(0.8421, grad_fn=<AddBackward0>)\n",
      "tensor(0.7361, grad_fn=<AddBackward0>)\n",
      "tensor(0.6687, grad_fn=<AddBackward0>)\n",
      "tensor(0.6582, grad_fn=<AddBackward0>)\n",
      "tensor(0.6469, grad_fn=<AddBackward0>)\n",
      "tensor(0.5907, grad_fn=<AddBackward0>)\n",
      "tensor(0.5224, grad_fn=<AddBackward0>)\n",
      "tensor(0.4883, grad_fn=<AddBackward0>)\n",
      "tensor(0.4820, grad_fn=<AddBackward0>)\n",
      "tensor(0.4664, grad_fn=<AddBackward0>)\n",
      "tensor(0.4275, grad_fn=<AddBackward0>)\n",
      "tensor(0.3868, grad_fn=<AddBackward0>)\n",
      "tensor(0.3664, grad_fn=<AddBackward0>)\n",
      "tensor(0.3612, grad_fn=<AddBackward0>)\n",
      "tensor(0.3489, grad_fn=<AddBackward0>)\n",
      "tensor(0.3229, grad_fn=<AddBackward0>)\n",
      "tensor(0.2984, grad_fn=<AddBackward0>)\n",
      "tensor(0.2864, grad_fn=<AddBackward0>)\n",
      "tensor(0.2811, grad_fn=<AddBackward0>)\n",
      "tensor(0.2717, grad_fn=<AddBackward0>)\n",
      "tensor(0.2556, grad_fn=<AddBackward0>)\n",
      "tensor(0.2395, grad_fn=<AddBackward0>)\n",
      "tensor(0.2295, grad_fn=<AddBackward0>)\n",
      "tensor(0.2245, grad_fn=<AddBackward0>)\n",
      "tensor(0.2182, grad_fn=<AddBackward0>)\n",
      "tensor(0.2078, grad_fn=<AddBackward0>)\n",
      "tensor(0.1967, grad_fn=<AddBackward0>)\n",
      "tensor(0.1888, grad_fn=<AddBackward0>)\n",
      "tensor(0.1840, grad_fn=<AddBackward0>)\n",
      "tensor(0.1793, grad_fn=<AddBackward0>)\n",
      "tensor(0.1728, grad_fn=<AddBackward0>)\n",
      "tensor(0.1653, grad_fn=<AddBackward0>)\n",
      "tensor(0.1587, grad_fn=<AddBackward0>)\n",
      "tensor(0.1540, grad_fn=<AddBackward0>)\n",
      "tensor(0.1504, grad_fn=<AddBackward0>)\n",
      "tensor(0.1462, grad_fn=<AddBackward0>)\n",
      "tensor(0.1412, grad_fn=<AddBackward0>)\n",
      "tensor(0.1362, grad_fn=<AddBackward0>)\n",
      "tensor(0.1320, grad_fn=<AddBackward0>)\n",
      "tensor(0.1288, grad_fn=<AddBackward0>)\n",
      "tensor(0.1258, grad_fn=<AddBackward0>)\n",
      "tensor(0.1225, grad_fn=<AddBackward0>)\n",
      "tensor(0.1189, grad_fn=<AddBackward0>)\n",
      "tensor(0.1154, grad_fn=<AddBackward0>)\n",
      "tensor(0.1124, grad_fn=<AddBackward0>)\n",
      "tensor(0.1099, grad_fn=<AddBackward0>)\n",
      "tensor(0.1075, grad_fn=<AddBackward0>)\n",
      "tensor(0.1050, grad_fn=<AddBackward0>)\n",
      "tensor(0.1024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0998, grad_fn=<AddBackward0>)\n",
      "tensor(0.0976, grad_fn=<AddBackward0>)\n",
      "tensor(0.0955, grad_fn=<AddBackward0>)\n",
      "tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "tensor(0.0685, grad_fn=<AddBackward0>)\n",
      "tensor(0.0674, grad_fn=<AddBackward0>)\n",
      "tensor(0.0662, grad_fn=<AddBackward0>)\n",
      "tensor(0.0651, grad_fn=<AddBackward0>)\n",
      "tensor(0.0641, grad_fn=<AddBackward0>)\n",
      "tensor(0.0630, grad_fn=<AddBackward0>)\n",
      "tensor(0.0620, grad_fn=<AddBackward0>)\n",
      "tensor(0.0610, grad_fn=<AddBackward0>)\n",
      "tensor(0.0600, grad_fn=<AddBackward0>)\n",
      "tensor(0.0590, grad_fn=<AddBackward0>)\n",
      "tensor(0.0581, grad_fn=<AddBackward0>)\n",
      "tensor(0.0572, grad_fn=<AddBackward0>)\n",
      "tensor(0.0564, grad_fn=<AddBackward0>)\n",
      "tensor(0.0555, grad_fn=<AddBackward0>)\n",
      "tensor(0.0547, grad_fn=<AddBackward0>)\n",
      "tensor(0.0539, grad_fn=<AddBackward0>)\n",
      "tensor(0.0531, grad_fn=<AddBackward0>)\n",
      "tensor(0.0523, grad_fn=<AddBackward0>)\n",
      "tensor(0.0515, grad_fn=<AddBackward0>)\n",
      "tensor(0.0508, grad_fn=<AddBackward0>)\n",
      "tensor(0.0501, grad_fn=<AddBackward0>)\n",
      "tensor(0.0494, grad_fn=<AddBackward0>)\n",
      "tensor(0.0487, grad_fn=<AddBackward0>)\n",
      "tensor(0.0480, grad_fn=<AddBackward0>)\n",
      "tensor(0.0473, grad_fn=<AddBackward0>)\n",
      "tensor(0.0467, grad_fn=<AddBackward0>)\n",
      "tensor(0.0461, grad_fn=<AddBackward0>)\n",
      "tensor(0.0455, grad_fn=<AddBackward0>)\n",
      "tensor(0.0448, grad_fn=<AddBackward0>)\n",
      "tensor(0.0443, grad_fn=<AddBackward0>)\n",
      "tensor(0.0437, grad_fn=<AddBackward0>)\n",
      "tensor(0.0431, grad_fn=<AddBackward0>)\n",
      "tensor(0.0426, grad_fn=<AddBackward0>)\n",
      "tensor(0.0420, grad_fn=<AddBackward0>)\n",
      "tensor(0.0415, grad_fn=<AddBackward0>)\n",
      "tensor(0.0409, grad_fn=<AddBackward0>)\n",
      "tensor(0.0404, grad_fn=<AddBackward0>)\n",
      "tensor(0.0399, grad_fn=<AddBackward0>)\n",
      "tensor(0.0394, grad_fn=<AddBackward0>)\n",
      "tensor(0.0390, grad_fn=<AddBackward0>)\n",
      "tensor(0.0385, grad_fn=<AddBackward0>)\n",
      "tensor(0.0380, grad_fn=<AddBackward0>)\n",
      "tensor(0.0376, grad_fn=<AddBackward0>)\n",
      "tensor(0.0371, grad_fn=<AddBackward0>)\n",
      "tensor(0.0367, grad_fn=<AddBackward0>)\n",
      "tensor(0.0362, grad_fn=<AddBackward0>)\n",
      "tensor(0.0358, grad_fn=<AddBackward0>)\n",
      "tensor(0.0354, grad_fn=<AddBackward0>)\n",
      "tensor(0.0350, grad_fn=<AddBackward0>)\n",
      "tensor(0.0346, grad_fn=<AddBackward0>)\n",
      "tensor(0.0342, grad_fn=<AddBackward0>)\n",
      "tensor(0.0338, grad_fn=<AddBackward0>)\n",
      "tensor(0.0334, grad_fn=<AddBackward0>)\n",
      "tensor(0.0331, grad_fn=<AddBackward0>)\n",
      "tensor(0.0327, grad_fn=<AddBackward0>)\n",
      "tensor(0.0323, grad_fn=<AddBackward0>)\n",
      "tensor(0.0320, grad_fn=<AddBackward0>)\n",
      "tensor(0.0316, grad_fn=<AddBackward0>)\n",
      "tensor(0.0313, grad_fn=<AddBackward0>)\n",
      "tensor(0.0309, grad_fn=<AddBackward0>)\n",
      "tensor(0.0306, grad_fn=<AddBackward0>)\n",
      "tensor(0.0303, grad_fn=<AddBackward0>)\n",
      "tensor(0.0300, grad_fn=<AddBackward0>)\n",
      "tensor(0.0296, grad_fn=<AddBackward0>)\n",
      "tensor(0.0293, grad_fn=<AddBackward0>)\n",
      "tensor(0.0290, grad_fn=<AddBackward0>)\n",
      "tensor(0.0287, grad_fn=<AddBackward0>)\n",
      "tensor(0.0284, grad_fn=<AddBackward0>)\n",
      "tensor(0.0281, grad_fn=<AddBackward0>)\n",
      "tensor(0.0279, grad_fn=<AddBackward0>)\n",
      "tensor(0.0276, grad_fn=<AddBackward0>)\n",
      "tensor(0.0273, grad_fn=<AddBackward0>)\n",
      "tensor(0.0270, grad_fn=<AddBackward0>)\n",
      "tensor(0.0268, grad_fn=<AddBackward0>)\n",
      "tensor(0.0265, grad_fn=<AddBackward0>)\n",
      "tensor(0.0262, grad_fn=<AddBackward0>)\n",
      "tensor(0.0260, grad_fn=<AddBackward0>)\n",
      "tensor(0.0257, grad_fn=<AddBackward0>)\n",
      "tensor(0.0255, grad_fn=<AddBackward0>)\n",
      "tensor(0.0252, grad_fn=<AddBackward0>)\n",
      "tensor(0.0250, grad_fn=<AddBackward0>)\n",
      "tensor(0.0248, grad_fn=<AddBackward0>)\n",
      "tensor(0.0245, grad_fn=<AddBackward0>)\n",
      "tensor(0.0243, grad_fn=<AddBackward0>)\n",
      "tensor(0.0241, grad_fn=<AddBackward0>)\n",
      "tensor(0.0238, grad_fn=<AddBackward0>)\n",
      "tensor(0.0236, grad_fn=<AddBackward0>)\n",
      "tensor(0.0234, grad_fn=<AddBackward0>)\n",
      "tensor(0.0232, grad_fn=<AddBackward0>)\n",
      "tensor(0.0230, grad_fn=<AddBackward0>)\n",
      "tensor(0.0228, grad_fn=<AddBackward0>)\n",
      "tensor(0.0226, grad_fn=<AddBackward0>)\n",
      "tensor(0.0224, grad_fn=<AddBackward0>)\n",
      "tensor(0.0222, grad_fn=<AddBackward0>)\n",
      "tensor(0.0220, grad_fn=<AddBackward0>)\n",
      "tensor(0.0218, grad_fn=<AddBackward0>)\n",
      "tensor(0.0216, grad_fn=<AddBackward0>)\n",
      "tensor(0.0214, grad_fn=<AddBackward0>)\n",
      "tensor(0.0212, grad_fn=<AddBackward0>)\n",
      "tensor(0.0210, grad_fn=<AddBackward0>)\n",
      "tensor(0.0208, grad_fn=<AddBackward0>)\n",
      "tensor(0.0206, grad_fn=<AddBackward0>)\n",
      "tensor(0.0205, grad_fn=<AddBackward0>)\n",
      "tensor(0.0203, grad_fn=<AddBackward0>)\n",
      "tensor(0.0201, grad_fn=<AddBackward0>)\n",
      "tensor(0.0200, grad_fn=<AddBackward0>)\n",
      "tensor(0.0198, grad_fn=<AddBackward0>)\n",
      "tensor(0.0196, grad_fn=<AddBackward0>)\n",
      "tensor(0.0195, grad_fn=<AddBackward0>)\n",
      "tensor(0.0193, grad_fn=<AddBackward0>)\n",
      "tensor(0.0191, grad_fn=<AddBackward0>)\n",
      "tensor(0.0190, grad_fn=<AddBackward0>)\n",
      "tensor(0.0188, grad_fn=<AddBackward0>)\n",
      "tensor(0.0187, grad_fn=<AddBackward0>)\n",
      "tensor(0.0185, grad_fn=<AddBackward0>)\n",
      "tensor(0.0184, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0182, grad_fn=<AddBackward0>)\n",
      "tensor(0.0181, grad_fn=<AddBackward0>)\n",
      "tensor(0.0179, grad_fn=<AddBackward0>)\n",
      "tensor(0.0178, grad_fn=<AddBackward0>)\n",
      "tensor(0.0176, grad_fn=<AddBackward0>)\n",
      "tensor(0.0175, grad_fn=<AddBackward0>)\n",
      "tensor(0.0174, grad_fn=<AddBackward0>)\n",
      "tensor(0.0172, grad_fn=<AddBackward0>)\n",
      "tensor(0.0171, grad_fn=<AddBackward0>)\n",
      "tensor(0.0170, grad_fn=<AddBackward0>)\n",
      "tensor(0.0168, grad_fn=<AddBackward0>)\n",
      "tensor(0.0167, grad_fn=<AddBackward0>)\n",
      "tensor(0.0166, grad_fn=<AddBackward0>)\n",
      "tensor(0.0165, grad_fn=<AddBackward0>)\n",
      "tensor(0.0163, grad_fn=<AddBackward0>)\n",
      "tensor(0.0162, grad_fn=<AddBackward0>)\n",
      "tensor(0.0161, grad_fn=<AddBackward0>)\n",
      "tensor(0.0160, grad_fn=<AddBackward0>)\n",
      "tensor(0.0158, grad_fn=<AddBackward0>)\n",
      "tensor(0.0157, grad_fn=<AddBackward0>)\n",
      "tensor(0.0156, grad_fn=<AddBackward0>)\n",
      "tensor(0.0155, grad_fn=<AddBackward0>)\n",
      "tensor(0.0154, grad_fn=<AddBackward0>)\n",
      "tensor(0.0153, grad_fn=<AddBackward0>)\n",
      "tensor(0.0152, grad_fn=<AddBackward0>)\n",
      "tensor(0.0151, grad_fn=<AddBackward0>)\n",
      "tensor(0.0149, grad_fn=<AddBackward0>)\n",
      "tensor(0.0148, grad_fn=<AddBackward0>)\n",
      "tensor(0.0147, grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, grad_fn=<AddBackward0>)\n",
      "tensor(0.0145, grad_fn=<AddBackward0>)\n",
      "tensor(0.0144, grad_fn=<AddBackward0>)\n",
      "tensor(0.0143, grad_fn=<AddBackward0>)\n",
      "tensor(0.0142, grad_fn=<AddBackward0>)\n",
      "tensor(0.0141, grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, grad_fn=<AddBackward0>)\n",
      "tensor(0.0139, grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, grad_fn=<AddBackward0>)\n",
      "tensor(0.0134, grad_fn=<AddBackward0>)\n",
      "tensor(0.0133, grad_fn=<AddBackward0>)\n",
      "tensor(0.0132, grad_fn=<AddBackward0>)\n",
      "tensor(0.0131, grad_fn=<AddBackward0>)\n",
      "tensor(0.0130, grad_fn=<AddBackward0>)\n",
      "tensor(0.0129, grad_fn=<AddBackward0>)\n",
      "tensor(0.0128, grad_fn=<AddBackward0>)\n",
      "tensor(0.0127, grad_fn=<AddBackward0>)\n",
      "tensor(0.0127, grad_fn=<AddBackward0>)\n",
      "tensor(0.0126, grad_fn=<AddBackward0>)\n",
      "tensor(0.0125, grad_fn=<AddBackward0>)\n",
      "tensor(0.0124, grad_fn=<AddBackward0>)\n",
      "tensor(0.0123, grad_fn=<AddBackward0>)\n",
      "tensor(0.0123, grad_fn=<AddBackward0>)\n",
      "tensor(0.0122, grad_fn=<AddBackward0>)\n",
      "tensor(0.0121, grad_fn=<AddBackward0>)\n",
      "tensor(0.0120, grad_fn=<AddBackward0>)\n",
      "tensor(0.0119, grad_fn=<AddBackward0>)\n",
      "tensor(0.0119, grad_fn=<AddBackward0>)\n",
      "tensor(0.0118, grad_fn=<AddBackward0>)\n",
      "tensor(0.0117, grad_fn=<AddBackward0>)\n",
      "tensor(0.0116, grad_fn=<AddBackward0>)\n",
      "tensor(0.0116, grad_fn=<AddBackward0>)\n",
      "tensor(0.0115, grad_fn=<AddBackward0>)\n",
      "tensor(0.0114, grad_fn=<AddBackward0>)\n",
      "tensor(0.0114, grad_fn=<AddBackward0>)\n",
      "tensor(0.0113, grad_fn=<AddBackward0>)\n",
      "tensor(0.0112, grad_fn=<AddBackward0>)\n",
      "tensor(0.0111, grad_fn=<AddBackward0>)\n",
      "tensor(0.0111, grad_fn=<AddBackward0>)\n",
      "tensor(0.0110, grad_fn=<AddBackward0>)\n",
      "tensor(0.0109, grad_fn=<AddBackward0>)\n",
      "tensor(0.0109, grad_fn=<AddBackward0>)\n",
      "tensor(0.0108, grad_fn=<AddBackward0>)\n",
      "tensor(0.0107, grad_fn=<AddBackward0>)\n",
      "tensor(0.0107, grad_fn=<AddBackward0>)\n",
      "tensor(0.0106, grad_fn=<AddBackward0>)\n",
      "tensor(0.0106, grad_fn=<AddBackward0>)\n",
      "tensor(0.0105, grad_fn=<AddBackward0>)\n",
      "tensor(0.0104, grad_fn=<AddBackward0>)\n",
      "tensor(0.0104, grad_fn=<AddBackward0>)\n",
      "tensor(0.0103, grad_fn=<AddBackward0>)\n",
      "tensor(0.0102, grad_fn=<AddBackward0>)\n",
      "tensor(0.0102, grad_fn=<AddBackward0>)\n",
      "tensor(0.0101, grad_fn=<AddBackward0>)\n",
      "tensor(0.0101, grad_fn=<AddBackward0>)\n",
      "tensor(0.0100, grad_fn=<AddBackward0>)\n",
      "tensor(0.0100, grad_fn=<AddBackward0>)\n",
      "tensor(0.0099, grad_fn=<AddBackward0>)\n",
      "tensor(0.0098, grad_fn=<AddBackward0>)\n",
      "tensor(0.0098, grad_fn=<AddBackward0>)\n",
      "tensor(0.0097, grad_fn=<AddBackward0>)\n",
      "tensor(0.0097, grad_fn=<AddBackward0>)\n",
      "tensor(0.0096, grad_fn=<AddBackward0>)\n",
      "tensor(0.0096, grad_fn=<AddBackward0>)\n",
      "tensor(0.0095, grad_fn=<AddBackward0>)\n",
      "tensor(0.0095, grad_fn=<AddBackward0>)\n",
      "tensor(0.0094, grad_fn=<AddBackward0>)\n",
      "tensor(0.0094, grad_fn=<AddBackward0>)\n",
      "tensor(0.0093, grad_fn=<AddBackward0>)\n",
      "tensor(0.0092, grad_fn=<AddBackward0>)\n",
      "tensor(0.0092, grad_fn=<AddBackward0>)\n",
      "tensor(0.0091, grad_fn=<AddBackward0>)\n",
      "tensor(0.0091, grad_fn=<AddBackward0>)\n",
      "tensor(0.0090, grad_fn=<AddBackward0>)\n",
      "tensor(0.0090, grad_fn=<AddBackward0>)\n",
      "tensor(0.0089, grad_fn=<AddBackward0>)\n",
      "tensor(0.0089, grad_fn=<AddBackward0>)\n",
      "tensor(0.0088, grad_fn=<AddBackward0>)\n",
      "tensor(0.0088, grad_fn=<AddBackward0>)\n",
      "tensor(0.0088, grad_fn=<AddBackward0>)\n",
      "tensor(0.0087, grad_fn=<AddBackward0>)\n",
      "tensor(0.0087, grad_fn=<AddBackward0>)\n",
      "tensor(0.0086, grad_fn=<AddBackward0>)\n",
      "tensor(0.0086, grad_fn=<AddBackward0>)\n",
      "tensor(0.0085, grad_fn=<AddBackward0>)\n",
      "tensor(0.0085, grad_fn=<AddBackward0>)\n",
      "tensor(0.0084, grad_fn=<AddBackward0>)\n",
      "tensor(0.0084, grad_fn=<AddBackward0>)\n",
      "tensor(0.0083, grad_fn=<AddBackward0>)\n",
      "tensor(0.0083, grad_fn=<AddBackward0>)\n",
      "tensor(0.0083, grad_fn=<AddBackward0>)\n",
      "tensor(0.0082, grad_fn=<AddBackward0>)\n",
      "tensor(0.0082, grad_fn=<AddBackward0>)\n",
      "tensor(0.0081, grad_fn=<AddBackward0>)\n",
      "tensor(0.0081, grad_fn=<AddBackward0>)\n",
      "tensor(0.0080, grad_fn=<AddBackward0>)\n",
      "tensor(0.0080, grad_fn=<AddBackward0>)\n",
      "tensor(0.0080, grad_fn=<AddBackward0>)\n",
      "tensor(0.0079, grad_fn=<AddBackward0>)\n",
      "tensor(0.0079, grad_fn=<AddBackward0>)\n",
      "tensor(0.0078, grad_fn=<AddBackward0>)\n",
      "tensor(0.0078, grad_fn=<AddBackward0>)\n",
      "tensor(0.0078, grad_fn=<AddBackward0>)\n",
      "tensor(0.0077, grad_fn=<AddBackward0>)\n",
      "tensor(0.0077, grad_fn=<AddBackward0>)\n",
      "tensor(0.0076, grad_fn=<AddBackward0>)\n",
      "tensor(0.0076, grad_fn=<AddBackward0>)\n",
      "tensor(0.0076, grad_fn=<AddBackward0>)\n",
      "tensor(0.0075, grad_fn=<AddBackward0>)\n",
      "tensor(0.0075, grad_fn=<AddBackward0>)\n",
      "tensor(0.0075, grad_fn=<AddBackward0>)\n",
      "tensor(0.0074, grad_fn=<AddBackward0>)\n",
      "tensor(0.0074, grad_fn=<AddBackward0>)\n",
      "tensor(0.0073, grad_fn=<AddBackward0>)\n",
      "tensor(0.0073, grad_fn=<AddBackward0>)\n",
      "tensor(0.0073, grad_fn=<AddBackward0>)\n",
      "tensor(0.0072, grad_fn=<AddBackward0>)\n",
      "tensor(0.0072, grad_fn=<AddBackward0>)\n",
      "tensor(0.0072, grad_fn=<AddBackward0>)\n",
      "tensor(0.0071, grad_fn=<AddBackward0>)\n",
      "tensor(0.0071, grad_fn=<AddBackward0>)\n",
      "tensor(0.0071, grad_fn=<AddBackward0>)\n",
      "tensor(0.0070, grad_fn=<AddBackward0>)\n",
      "tensor(0.0070, grad_fn=<AddBackward0>)\n",
      "tensor(0.0070, grad_fn=<AddBackward0>)\n",
      "tensor(0.0069, grad_fn=<AddBackward0>)\n",
      "tensor(0.0069, grad_fn=<AddBackward0>)\n",
      "tensor(0.0069, grad_fn=<AddBackward0>)\n",
      "tensor(0.0068, grad_fn=<AddBackward0>)\n",
      "tensor(0.0068, grad_fn=<AddBackward0>)\n",
      "tensor(0.0068, grad_fn=<AddBackward0>)\n",
      "tensor(0.0067, grad_fn=<AddBackward0>)\n",
      "tensor(0.0067, grad_fn=<AddBackward0>)\n",
      "tensor(0.0067, grad_fn=<AddBackward0>)\n",
      "tensor(0.0066, grad_fn=<AddBackward0>)\n",
      "tensor(0.0066, grad_fn=<AddBackward0>)\n",
      "tensor(0.0066, grad_fn=<AddBackward0>)\n",
      "tensor(0.0066, grad_fn=<AddBackward0>)\n",
      "tensor(0.0065, grad_fn=<AddBackward0>)\n",
      "tensor(0.0065, grad_fn=<AddBackward0>)\n",
      "tensor(0.0065, grad_fn=<AddBackward0>)\n",
      "tensor(0.0064, grad_fn=<AddBackward0>)\n",
      "tensor(0.0064, grad_fn=<AddBackward0>)\n",
      "tensor(0.0064, grad_fn=<AddBackward0>)\n",
      "tensor(0.0063, grad_fn=<AddBackward0>)\n",
      "tensor(0.0063, grad_fn=<AddBackward0>)\n",
      "tensor(0.0063, grad_fn=<AddBackward0>)\n",
      "tensor(0.0063, grad_fn=<AddBackward0>)\n",
      "tensor(0.0062, grad_fn=<AddBackward0>)\n",
      "tensor(0.0062, grad_fn=<AddBackward0>)\n",
      "tensor(0.0062, grad_fn=<AddBackward0>)\n",
      "tensor(0.0062, grad_fn=<AddBackward0>)\n",
      "tensor(0.0061, grad_fn=<AddBackward0>)\n",
      "tensor(0.0061, grad_fn=<AddBackward0>)\n",
      "tensor(0.0061, grad_fn=<AddBackward0>)\n",
      "tensor(0.0060, grad_fn=<AddBackward0>)\n",
      "tensor(0.0060, grad_fn=<AddBackward0>)\n",
      "tensor(0.0060, grad_fn=<AddBackward0>)\n",
      "tensor(0.0060, grad_fn=<AddBackward0>)\n",
      "tensor(0.0059, grad_fn=<AddBackward0>)\n",
      "tensor(0.0059, grad_fn=<AddBackward0>)\n",
      "tensor(0.0059, grad_fn=<AddBackward0>)\n",
      "tensor(0.0059, grad_fn=<AddBackward0>)\n",
      "tensor(0.0058, grad_fn=<AddBackward0>)\n",
      "tensor(0.0058, grad_fn=<AddBackward0>)\n",
      "tensor(0.0058, grad_fn=<AddBackward0>)\n",
      "tensor(0.0058, grad_fn=<AddBackward0>)\n",
      "tensor(0.0057, grad_fn=<AddBackward0>)\n",
      "tensor(0.0057, grad_fn=<AddBackward0>)\n",
      "tensor(0.0057, grad_fn=<AddBackward0>)\n",
      "tensor(0.0057, grad_fn=<AddBackward0>)\n",
      "tensor(0.0056, grad_fn=<AddBackward0>)\n",
      "tensor(0.0056, grad_fn=<AddBackward0>)\n",
      "tensor(0.0056, grad_fn=<AddBackward0>)\n",
      "tensor(0.0056, grad_fn=<AddBackward0>)\n",
      "tensor(0.0055, grad_fn=<AddBackward0>)\n",
      "tensor(0.0055, grad_fn=<AddBackward0>)\n",
      "tensor(0.0055, grad_fn=<AddBackward0>)\n",
      "tensor(0.0055, grad_fn=<AddBackward0>)\n",
      "tensor(0.0054, grad_fn=<AddBackward0>)\n",
      "tensor(0.0054, grad_fn=<AddBackward0>)\n",
      "tensor(0.0054, grad_fn=<AddBackward0>)\n",
      "tensor(0.0054, grad_fn=<AddBackward0>)\n",
      "tensor(0.0054, grad_fn=<AddBackward0>)\n",
      "tensor(0.0053, grad_fn=<AddBackward0>)\n",
      "tensor(0.0053, grad_fn=<AddBackward0>)\n",
      "tensor(0.0053, grad_fn=<AddBackward0>)\n",
      "tensor(0.0053, grad_fn=<AddBackward0>)\n",
      "tensor(0.0052, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0052, grad_fn=<AddBackward0>)\n",
      "tensor(0.0052, grad_fn=<AddBackward0>)\n",
      "tensor(0.0052, grad_fn=<AddBackward0>)\n",
      "tensor(0.0052, grad_fn=<AddBackward0>)\n",
      "tensor(0.0051, grad_fn=<AddBackward0>)\n",
      "tensor(0.0051, grad_fn=<AddBackward0>)\n",
      "tensor(0.0051, grad_fn=<AddBackward0>)\n",
      "tensor(0.0051, grad_fn=<AddBackward0>)\n",
      "tensor(0.0051, grad_fn=<AddBackward0>)\n",
      "tensor(0.0050, grad_fn=<AddBackward0>)\n",
      "tensor(0.0050, grad_fn=<AddBackward0>)\n",
      "tensor(0.0050, grad_fn=<AddBackward0>)\n",
      "tensor(0.0050, grad_fn=<AddBackward0>)\n",
      "tensor(0.0050, grad_fn=<AddBackward0>)\n",
      "tensor(0.0049, grad_fn=<AddBackward0>)\n",
      "tensor(0.0049, grad_fn=<AddBackward0>)\n",
      "tensor(0.0049, grad_fn=<AddBackward0>)\n",
      "tensor(0.0049, grad_fn=<AddBackward0>)\n",
      "tensor(0.0049, grad_fn=<AddBackward0>)\n",
      "tensor(0.0048, grad_fn=<AddBackward0>)\n",
      "tensor(0.0048, grad_fn=<AddBackward0>)\n",
      "tensor(0.0048, grad_fn=<AddBackward0>)\n",
      "tensor(0.0048, grad_fn=<AddBackward0>)\n",
      "tensor(0.0048, grad_fn=<AddBackward0>)\n",
      "tensor(0.0048, grad_fn=<AddBackward0>)\n",
      "tensor(0.0047, grad_fn=<AddBackward0>)\n",
      "tensor(0.0047, grad_fn=<AddBackward0>)\n",
      "tensor(0.0047, grad_fn=<AddBackward0>)\n",
      "tensor(0.0047, grad_fn=<AddBackward0>)\n",
      "tensor(0.0047, grad_fn=<AddBackward0>)\n",
      "tensor(0.0046, grad_fn=<AddBackward0>)\n",
      "tensor(0.0046, grad_fn=<AddBackward0>)\n",
      "tensor(0.0046, grad_fn=<AddBackward0>)\n",
      "tensor(0.0046, grad_fn=<AddBackward0>)\n",
      "tensor(0.0046, grad_fn=<AddBackward0>)\n",
      "tensor(0.0046, grad_fn=<AddBackward0>)\n",
      "tensor(0.0045, grad_fn=<AddBackward0>)\n",
      "tensor(0.0045, grad_fn=<AddBackward0>)\n",
      "tensor(0.0045, grad_fn=<AddBackward0>)\n",
      "tensor(0.0045, grad_fn=<AddBackward0>)\n",
      "tensor(0.0045, grad_fn=<AddBackward0>)\n",
      "tensor(0.0045, grad_fn=<AddBackward0>)\n",
      "tensor(0.0044, grad_fn=<AddBackward0>)\n",
      "tensor(0.0044, grad_fn=<AddBackward0>)\n",
      "tensor(0.0044, grad_fn=<AddBackward0>)\n",
      "tensor(0.0044, grad_fn=<AddBackward0>)\n",
      "tensor(0.0044, grad_fn=<AddBackward0>)\n",
      "tensor(0.0044, grad_fn=<AddBackward0>)\n",
      "tensor(0.0043, grad_fn=<AddBackward0>)\n",
      "tensor(0.0043, grad_fn=<AddBackward0>)\n",
      "tensor(0.0043, grad_fn=<AddBackward0>)\n",
      "tensor(0.0043, grad_fn=<AddBackward0>)\n",
      "tensor(0.0043, grad_fn=<AddBackward0>)\n",
      "tensor(0.0043, grad_fn=<AddBackward0>)\n",
      "tensor(0.0042, grad_fn=<AddBackward0>)\n",
      "tensor(0.0042, grad_fn=<AddBackward0>)\n",
      "tensor(0.0042, grad_fn=<AddBackward0>)\n",
      "tensor(0.0042, grad_fn=<AddBackward0>)\n",
      "tensor(0.0042, grad_fn=<AddBackward0>)\n",
      "tensor(0.0042, grad_fn=<AddBackward0>)\n",
      "tensor(0.0041, grad_fn=<AddBackward0>)\n",
      "tensor(0.0041, grad_fn=<AddBackward0>)\n",
      "tensor(0.0041, grad_fn=<AddBackward0>)\n",
      "tensor(0.0041, grad_fn=<AddBackward0>)\n",
      "tensor(0.0041, grad_fn=<AddBackward0>)\n",
      "tensor(0.0041, grad_fn=<AddBackward0>)\n",
      "tensor(0.0041, grad_fn=<AddBackward0>)\n",
      "tensor(0.0040, grad_fn=<AddBackward0>)\n",
      "tensor(0.0040, grad_fn=<AddBackward0>)\n",
      "tensor(0.0040, grad_fn=<AddBackward0>)\n",
      "tensor(0.0040, grad_fn=<AddBackward0>)\n",
      "tensor(0.0040, grad_fn=<AddBackward0>)\n",
      "tensor(0.0040, grad_fn=<AddBackward0>)\n",
      "tensor(0.0040, grad_fn=<AddBackward0>)\n",
      "tensor(0.0039, grad_fn=<AddBackward0>)\n",
      "tensor(0.0039, grad_fn=<AddBackward0>)\n",
      "tensor(0.0039, grad_fn=<AddBackward0>)\n",
      "tensor(0.0039, grad_fn=<AddBackward0>)\n",
      "tensor(0.0039, grad_fn=<AddBackward0>)\n",
      "tensor(0.0039, grad_fn=<AddBackward0>)\n",
      "tensor(0.0039, grad_fn=<AddBackward0>)\n",
      "tensor(0.0039, grad_fn=<AddBackward0>)\n",
      "tensor(0.0038, grad_fn=<AddBackward0>)\n",
      "tensor(0.0038, grad_fn=<AddBackward0>)\n",
      "tensor(0.0038, grad_fn=<AddBackward0>)\n",
      "tensor(0.0038, grad_fn=<AddBackward0>)\n",
      "tensor(0.0038, grad_fn=<AddBackward0>)\n",
      "tensor(0.0038, grad_fn=<AddBackward0>)\n",
      "tensor(0.0038, grad_fn=<AddBackward0>)\n",
      "tensor(0.0037, grad_fn=<AddBackward0>)\n",
      "tensor(0.0037, grad_fn=<AddBackward0>)\n",
      "tensor(0.0037, grad_fn=<AddBackward0>)\n",
      "tensor(0.0037, grad_fn=<AddBackward0>)\n",
      "tensor(0.0037, grad_fn=<AddBackward0>)\n",
      "tensor(0.0037, grad_fn=<AddBackward0>)\n",
      "tensor(0.0037, grad_fn=<AddBackward0>)\n",
      "tensor(0.0037, grad_fn=<AddBackward0>)\n",
      "tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "tensor(0.0035, grad_fn=<AddBackward0>)\n",
      "tensor(0.0035, grad_fn=<AddBackward0>)\n",
      "tensor(0.0035, grad_fn=<AddBackward0>)\n",
      "tensor(0.0035, grad_fn=<AddBackward0>)\n",
      "tensor(0.0035, grad_fn=<AddBackward0>)\n",
      "tensor(0.0035, grad_fn=<AddBackward0>)\n",
      "tensor(0.0035, grad_fn=<AddBackward0>)\n",
      "tensor(0.0035, grad_fn=<AddBackward0>)\n",
      "tensor(0.0035, grad_fn=<AddBackward0>)\n",
      "tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "tensor(0.0033, grad_fn=<AddBackward0>)\n",
      "tensor(0.0033, grad_fn=<AddBackward0>)\n",
      "tensor(0.0033, grad_fn=<AddBackward0>)\n",
      "tensor(0.0033, grad_fn=<AddBackward0>)\n",
      "tensor(0.0033, grad_fn=<AddBackward0>)\n",
      "tensor(0.0033, grad_fn=<AddBackward0>)\n",
      "tensor(0.0033, grad_fn=<AddBackward0>)\n",
      "tensor(0.0033, grad_fn=<AddBackward0>)\n",
      "tensor(0.0033, grad_fn=<AddBackward0>)\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0025, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0020, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "num_epochs=1000\n",
    "epoch=0\n",
    "for epoch in range(num_epochs):\n",
    "    loss=0\n",
    "    for i in range(20):\n",
    "        output=model1(x[i])\n",
    "        loss+=criterion(output[0],y[i])\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "420487da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 tensor([-0.7510])\n",
      "b1 tensor([3.4103])\n",
      "t11 tensor([-4.3939])\n",
      "b11 tensor([-2.3771])\n",
      "t12 tensor([4.6046])\n",
      "b12 tensor([1.7004])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model1.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0f57352",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0.], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1., 0.], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1., 0.], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1., 0.], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1., 0.], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1., 0.], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.0000e+00, 5.4090e-43], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.0000e+00, 3.0051e-27], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.0000e+00, 2.2699e-14], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([9.9977e-01, 2.3320e-04], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([3.0658e-04, 9.9969e-01], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.6125e-08, 1.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([6.2325e-10, 1.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.7706e-08, 1.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([3.6963e-04, 9.9963e-01], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([9.9975e-01, 2.5262e-04], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.0000e+00, 1.4652e-14], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.0000e+00, 8.4214e-28], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.0000e+00, 4.7644e-44], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1., 0.], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srika\\AppData\\Local\\Temp\\ipykernel_5336\\764618393.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  f=self.softmax(f)\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(model1(x[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1651f0ca",
   "metadata": {},
   "source": [
    "### For 2 D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0200fa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=np.arange(-10,10)\n",
    "x2=np.arange(10,30)\n",
    "x=np.vstack((x1.T,x2.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78c60b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.random.randn(20,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "118272ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2054849 ,  0.44982731],\n",
       "       [-1.12585669,  0.23725532],\n",
       "       [ 0.3077817 , -0.98609494],\n",
       "       [ 0.90593091, -1.16985498],\n",
       "       [ 1.45661587,  0.43641423],\n",
       "       [-0.1720135 ,  0.44632114],\n",
       "       [ 0.0574967 ,  0.51352617],\n",
       "       [-1.65325237, -0.59153972],\n",
       "       [-1.71928127,  0.52935686],\n",
       "       [ 1.7443251 , -0.93387826],\n",
       "       [ 0.87255749,  1.18694602],\n",
       "       [ 0.03467632, -0.46456032],\n",
       "       [ 0.88525734, -0.77978981],\n",
       "       [-2.3937423 ,  1.0373066 ],\n",
       "       [ 0.2738266 , -0.74505807],\n",
       "       [-1.00738   ,  1.06071063],\n",
       "       [-1.16363736, -0.56595318],\n",
       "       [ 0.28025414, -0.00888372],\n",
       "       [ 0.00708492, -2.277088  ],\n",
       "       [ 0.53926414,  0.06574083]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cee3037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGdCAYAAADaPpOnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlj0lEQVR4nO3dfWxb5d3/8c9JOuxWS4zSLLFzE6hXnppl2k2D0qYTW7upIWXLgE0V/FC7MUG3pkJTqSq2gkSaSRDBeNJWmsIGtCjsVv9g3RbRRa00CmgNCyVkW0jpRgmka+2FNmCn25IM5/z+yG3fGDtpnPrYvpz3SzoS5/g69TcyrT+5no5l27YtAAAAQxRkuwAAAIBUEF4AAIBRCC8AAMAohBcAAGAUwgsAADAK4QUAABiF8AIAAIxCeAEAAEaZl+0C0m1iYkKnTp1SUVGRLMvKdjkAAGAGbNvWyMiIKioqVFAwfd9K3oWXU6dOqbKyMttlAACAWThx4oQuuuiiadvkXXgpKiqSNPnDFxcXZ7kaAAAwE+FwWJWVlbHv8enkXXiJDhUVFxcTXgAAMMxMpnwwYRcAABiF8AIAAIxCeAEAAEYhvAAAAKMQXgAAgFEILwAAwCiEFwAAYBTCCwAAMErebVIHAMhvkQlb3QPDGhoZVVmRW7X+EhUW8Cy7uYTwAgAwRmdfQC0d/QqERmPXfB63mhur1FDty2JlyCSGjQAARujsC6ipvScuuEhSMDSqpvYedfYFslQZMo3wAgDIeZEJWy0d/bKTvBa91tLRr8hEshbIN4QXAEDO6x4YTuhx+ThbUiA0qu6B4cwVhawhvAAAct7QyNTBZTbtYDbCCwAg55UVudPaDmYjvAAAcl6tv0Q+j1tTLYi2NLnqqNZfksmykCWEFwBAzisssNTcWCVJCQEmet7cWMV+L3ME4QUAYISGap/a1i2V1xM/NOT1uNW2bin7vMwhbFIHADBGQ7VPq6u87LA7xxFeAABGKSywVLd4YbbLQBYxbAQAAIxCzwuQZTxkDgBSQ3gBsoiHzAFA6hg2mqHIhK2u42f0m96T6jp+hudn4LzxkDkAmB16XmaA346Rbud6yJylyYfMra7yMoQEAJ9Az8s58NsxnMBD5gBg9ggv0+AR7HAKD5kDgNlzNLy8/PLLamxsVEVFhSzL0q9//etz3vPSSy+ppqZGbrdbn/3sZ7Vr1y4nS5wWvx3DKTxkDgBmz9Hw8s9//lNf+MIXtGPHjhm1HxgY0HXXXadrrrlGb7zxhu6++2794Ac/0PPPP+9kmVPit2M4hYfMAcDsOTphd82aNVqzZs2M2+/atUsXX3yxHnvsMUnSkiVLdOTIET300EP61re+5VCVU+O3Yzgl+pC5pvYeWVLc0CQPmQOA6eXUnJeuri7V19fHXbv22mt15MgR/ec//8l4Pfx2DCfxkDkAmJ2cWiodDAZVXl4ed628vFwfffSRTp8+LZ8v8R/zsbExjY2Nxc7D4XDa6uG3YziNh8wBQOpyqudFkiwr/h9t27aTXo9qbW2Vx+OJHZWVlWmth9+O4bToQ+au/+//Ut3ihQQXADiHnOp58Xq9CgaDcdeGhoY0b948LVyY/Ami27Zt05YtW2Ln4XDYkQDDb8cAAOSGnAovdXV16ujoiLt24MABXX311frUpz6V9B6XyyWXy+V4bTyCHQCA3ODosNHZs2fV29ur3t5eSZNLoXt7ezU4OChpstfk29/+dqz9xo0b9d5772nLli06evSonn76aT311FPaunWrk2UCAACDONrzcuTIEa1atSp2Hh3e+c53vqPdu3crEAjEgowk+f1+7d+/X3feeacef/xxVVRU6Kc//WlWlkkDAIDcZNnRGbF5IhwOy+PxKBQKqbi4ONvlAACAGUjl+zvnVhsBAABMh/ACAACMQngBAABGIbwAAACjEF4AAIBRCC8AAMAohBcAAGAUwgsAADAK4QUAABiF8AIAAIxCeAEAAEYhvAAAAKMQXgAAgFEILwAAwCiEFwAAYBTCCwAAMArhBQAAGIXwAgAAjEJ4AQAARiG8AAAAoxBeAACAUQgvAADAKIQXAABgFMILAAAwCuEFAAAYhfACAACMQngBAABGIbwAAACjEF4AAIBRCC8AAMAohBcAAGAUwgsAADAK4QUAABiF8AIAAIwyL9sFIL9EJmx1DwxraGRUZUVu1fpLVFhgZbssAEAeIbwgbTr7Amrp6FcgNBq75vO41dxYpYZqXxYrAwDkE4aNkBadfQE1tffEBRdJCoZG1dTeo86+QJYqAzIrMmGr6/gZ/ab3pLqOn1Fkws52SUDeoecF5y0yYaulo1/J/om2JVmSWjr6tbrKyxAS8hq9j0BmZKTnZefOnfL7/XK73aqpqdErr7wyZdtDhw7JsqyE46233spEqZiF7oHhhB6Xj7MlBUKj6h4YzlxRQIbR+whkjuPhZe/evdq8ebPuuecevfHGG7rmmmu0Zs0aDQ4OTnvfsWPHFAgEYsdll13mdKmYpaGRqYPLbNoBpjlX76M02fvIEBKQHo6Hl0ceeUS33Xabbr/9di1ZskSPPfaYKisr1dbWNu19ZWVl8nq9saOwsNDpUjFLZUXutLYDTEPvI5BZjoaX8fFxvf7666qvr4+7Xl9fr8OHD09771VXXSWfz6evfvWrevHFF6dsNzY2pnA4HHcgs2r9JfJ53JpqNoulyXH/Wn9JJssCMobeRyCzHA0vp0+fViQSUXl5edz18vJyBYPBpPf4fD49+eSTev755/WrX/1KV1xxhb761a/q5ZdfTtq+tbVVHo8ndlRWVqb958D0CgssNTdWSVJCgImeNzdWMVkXWefUSqB09j6yWgk4t4ysNrKs+C8t27YTrkVdccUVuuKKK2LndXV1OnHihB566CF96UtfSmi/bds2bdmyJXYeDocJMFnQUO1T27qlCSstvKy0QI5wciVQtPcxGBpNOu/F0uTfhXP1PrJaCTPBZqAOh5fS0lIVFhYm9LIMDQ0l9MZMZ/ny5Wpvb0/6msvlksvlOq86kR4N1T6trvLO+b9UyD3RlUCfDBbRlUBt65aeVziI9j42tffIkuLeZ6a9j07XiPxAwJ3k6LDRBRdcoJqaGh08eDDu+sGDB7VixYoZ/zlvvPGGfL6586GYrLDAUt3ihbr+v/9LdYsXElyQdZlaCRTtffR64oeGvB73OYMHq5UwEyzH/z+ODxtt2bJF69ev19VXX626ujo9+eSTGhwc1MaNGyVNDvucPHlSzz77rCTpscce06JFi/S5z31O4+Pjam9v1/PPP6/nn3/e6VIB5KFUVgLVLV54Xu81297HTNYIM7EZaDzHw8tNN92kM2fO6Mc//rECgYCqq6u1f/9+XXLJJZKkQCAQt+fL+Pi4tm7dqpMnT2r+/Pn63Oc+pxdeeEHXXXed06UCyEOZXgkU7X1MBauVcC4E3HgZmbC7adMmbdq0Kelru3fvjju/6667dNddd2WgKgBzgQn7EJlQI7KLgBuPBzMCyGsm7ENkQo3ILgJuPMILgLxmwj5EJtSI7CLgxiO8AMh757MSKFNMqBHZQ8CNZ9m2nVdr78LhsDwej0KhkIqLi7NdDoAcYsLmXibUiOzJ531eUvn+JrwAAGCQfA24qXx/Z2S1EQAASI/ZLMfPN8x5AQAARiG8AAAAoxBeAACAUQgvAADAKIQXAABgFMILAAAwCuEFAAAYhfACAACMwiZ1QBrl686XAJBLCC9AmuTzM0cAIJcwbASkQWdfQE3tPXHBRZKCoVE1tfeosy+QpcoAIP8QXoDzFJmw1dLRr2RPOI1ea+noV2Qir56BCgBZQ3gBzlP3wHBCj8vH2ZICoVF1DwxnrigAyGOEF+A8DY1MHVxm0w4AMD3CC3CeyorcaW0HAJge4QU4T7X+Evk8bk21INrS5KqjWn9JJssCgLxFeAHOU2GBpebGKklKCDDR8+bGKvZ7AYA0IbwAadBQ7VPbuqXyeuKHhrwet9rWLWWfFwBIIzapA9Kkodqn1VVedtgFAIcRXoA0KiywVLd4YbbLAIC8xrARAAAwCuEFAAAYhfACAACMQngBAABGYcIuAGBakQmbVXTIKYQXAMCUOvsCaunoj3v4qM/jVnNjFfsXIWsYNgIAJNXZF1BTe0/CU9ODoVE1tfeosy+Qpcow1xFeAAAJIhO2Wjr6ZSd5LXqtpaNfkYlkLQBnEV4AAAm6B4YTelw+zpYUCI2qe2A4c0UB/4vwAgBIMDQydXCZTTsgnQgvAIAEZUXuczdKoR2QThkJLzt37pTf75fb7VZNTY1eeeWVadu/9NJLqqmpkdvt1mc/+1nt2rUrE2UCQM6LTNjqOn5Gv+k9qa7jZxybc1LrL5HP49ZUC6ItTa46qvWXOPL+wHQcXyq9d+9ebd68WTt37tQXv/hFPfHEE1qzZo36+/t18cUXJ7QfGBjQddddpw0bNqi9vV1/+MMftGnTJn3mM5/Rt771LafLBYCclclly4UFlpobq9TU3iNLipu4Gw00zY1V7PeCrLBs23Z0qviyZcu0dOlStbW1xa4tWbJEN9xwg1pbWxPa//CHP9Rvf/tbHT16NHZt48aN+tOf/qSurq5zvl84HJbH41EoFFJxcXF6fggAyLLosuVP/oMdjQ5t65Y6su8K+7wgU1L5/na052V8fFyvv/66fvSjH8Vdr6+v1+HDh5Pe09XVpfr6+rhr1157rZ566in95z//0ac+9SnH6gWAXHSuZcuWJpctr67ypr0npKHap9VVXnbYRU5xNLycPn1akUhE5eXlcdfLy8sVDAaT3hMMBpO2/+ijj3T69Gn5fPFJf2xsTGNjY7HzcDicpuoBIDeksmy5bvHCtL9/YYHlyJ8LzFZGJuxaVnxCt2074dq52ie7Lkmtra3yeDyxo7KyMg0VA0DuYNkyEM/R8FJaWqrCwsKEXpahoaGE3pUor9ebtP28efO0cGFi8t+2bZtCoVDsOHHiRPp+AADIASxbBuI5Gl4uuOAC1dTU6ODBg3HXDx48qBUrViS9p66uLqH9gQMHdPXVVyed7+JyuVRcXBx3AEA+YdkyEM/xYaMtW7boF7/4hZ5++mkdPXpUd955pwYHB7Vx40ZJkz0n3/72t2PtN27cqPfee09btmzR0aNH9fTTT+upp57S1q1bnS4VAHJSdNmypIQAw7JlzEWO7/Ny00036cyZM/rxj3+sQCCg6upq7d+/X5dccokkKRAIaHBwMNbe7/dr//79uvPOO/X444+roqJCP/3pT9njBcCc1lDtU9u6pQnLlr0sW8Yc5Pg+L5nGPi8A8llkwmbZMvJSzuzzAgBIL5YtAzyYEQAAGIbwAgAAjEJ4AQAARiG8AAAAoxBeAACAUQgvAADAKIQXAABgFMILAAAwCuEFAAAYhfACAACMQngBAABGIbwAAACjEF4AAIBRCC8AAMAohBcAAGAUwgsAADAK4QUAABiF8AIAAIxCeAEAAEYhvAAAAKMQXgAAgFEILwAAwCiEFwAAYBTCCwAAMArhBQAAGIXwAgAAjEJ4AQAARiG8AAAAoxBeAACAUQgvAADAKIQXAABgFMILAAAwCuEFAAAYZV62CwCAfBCZsNU9MKyhkVGVFblV6y9RYYGV7bKAvER4AYDz1NkXUEtHvwKh0dg1n8et5sYqNVT7slgZkJ8YNgKA89DZF1BTe09ccJGkYGhUTe096uwLZKkyIH8RXgBgliITtlo6+mUneS16raWjX5GJZC0AzJaj4eWDDz7Q+vXr5fF45PF4tH79en344YfT3nPrrbfKsqy4Y/ny5U6WCQCz0j0wnNDj8nG2pEBoVN0Dw5krCpgDHJ3zcsstt+jvf/+7Ojs7JUnf+973tH79enV0dEx7X0NDg5555pnY+QUXXOBkmQAwK0MjUweX2bQDMDOOhZejR4+qs7NTr776qpYtWyZJ+vnPf666ujodO3ZMV1xxxZT3ulwueb1ep0oDgLQoK3KntR2AmXFs2Kirq0sejycWXCRp+fLl8ng8Onz48LT3Hjp0SGVlZbr88su1YcMGDQ0NTdl2bGxM4XA47gCATKj1l8jncWuqBdGWJlcd1fpLMlkWkPccCy/BYFBlZWUJ18vKyhQMBqe8b82aNXruuef0+9//Xg8//LBee+01feUrX9HY2FjS9q2trbE5NR6PR5WVlWn7GQBgOoUFlpobqyQpIcBEz5sbq9jvBUizlMPL9u3bEybUfvI4cuSIJMmyEv/C2rad9HrUTTfdpK997Wuqrq5WY2Ojfve73+mvf/2rXnjhhaTtt23bplAoFDtOnDiR6o8EALPWUO1T27ql8nrih4a8Hrfa1i1lnxfAASnPebnjjjt08803T9tm0aJF+vOf/6x//OMfCa+9//77Ki8vn/H7+Xw+XXLJJfrb3/6W9HWXyyWXyzXjPw9IJ3ZVhTQZYFZXefl/AciQlMNLaWmpSktLz9murq5OoVBI3d3dqq2tlST98Y9/VCgU0ooVK2b8fmfOnNGJEyfk8/HbC3ILu6ri4woLLNUtXpjtMoA5wbE5L0uWLFFDQ4M2bNigV199Va+++qo2bNigr3/963Erja688krt27dPknT27Flt3bpVXV1devfdd3Xo0CE1NjaqtLRUN954o1OlIkMiE7a6jp/Rb3pPquv4GaM37mJXVQDIHkf3eXnuuef0gx/8QPX19ZKkb3zjG9qxY0dcm2PHjikUCkmSCgsL9Ze//EXPPvusPvzwQ/l8Pq1atUp79+5VUVGRk6XCYfnUS3GuXVUtTe6qurrKy7ABADjAsm3b3F9/kwiHw/J4PAqFQiouLs52OdD/9VJ88n+06Ne6aZMau46f0f/7+avnbPc/G5YzjAAAM5TK9zfPNoKj8vHZL+yqCgDZRXiBo/Lx2S/sqgoA2UV4gaPysZeCXVUBILsIL3BUPvZSsKsqAGQX4QWOytdeCnZVBYDscXSpNBDtpWhq75ElxU3cNb2Xgl1VASA7WCqNjMinfV4AAOmXyvc3PS/ICHopAADpQnhBxvDsFwBAOjBhFwAAGIXwAgAAjEJ4AQAARmHOCwAYJDJhM/Edcx7hBQAMwZYDwCSGjQDAAJ19ATW19yQ86DQYGlVTe486+wJZqgzIPMILAOS4yIStlo5+JdtRNHqtpaNfkYm82nN0WpEJW13Hz+g3vSfVdfzMnPrZwbARAOS87oHhhB6Xj7MlBUKj6h4YnhN7KTF8BnpeACDHDY1MHVxm085kDJ9BIrwAQM4rK3Kfu1EK7UzF8BmiCC8AkONq/SXyedyaakG0pclhk1p/SSbLyrhUhs+Q3wgvAJDjCgssNTdWSVJCgImeNzdW5f1+LwyfIYrwAgAGaKj2qW3dUnk98UNDXo9bbeuWzomJqgyfIYrVRgBgiIZqn1ZXeefsDrvR4bNgaDTpvBdLk2Eu34fPQHgBAKMUFlhzYjl0MtHhs6b2HllSXICZS8NnYNgIAGAQhs8g0fMCADDMXB8+A+EFAGCguTx8BoaNAACAYQgvAADAKIQXAABgFOa8AACAGYlM2DkxUZrwAgAAzqmzL6CWjv6450v5PG41N1ZlfIk6w0YAAGBanX0BNbX3JDwYMxgaVVN7jzr7Ahmth/ACAACmFJmw1dLRn/SRDNFrLR39ikwka+EMwgsAAJhS98BwQo/Lx9mSAqFRdQ8MZ6wm5rwAgKFyZfIk8tvQyNTBZTbt0oHwAgAGyqXJk8hvZUXuczdKoV06ODpsdN9992nFihVasGCBLrzwwhndY9u2tm/froqKCs2fP18rV67Um2++6WSZAGCUXJs8ifxW6y+Rz+PWVH16liaDc62/JGM1ORpexsfHtXbtWjU1Nc34ngcffFCPPPKIduzYoddee01er1erV6/WyMiIg5UCgBlycfIk8lthgaXmxipJSggw0fPmxqqMDlk6Gl5aWlp055136vOf//yM2tu2rccee0z33HOPvvnNb6q6ulp79uzRv/71L/3yl790slQAMEIuTp5E/muo9qlt3VJ5PfFDQ16PW23rlmZ8qDKn5rwMDAwoGAyqvr4+ds3lcunLX/6yDh8+rO9///tZrA4Asi8XJ09ibmio9ml1lTcnJonnVHgJBoOSpPLy8rjr5eXleu+995LeMzY2prGxsdh5OBx2rkAAyLJcnDyJuaOwwFLd4oXZLiP1YaPt27fLsqxpjyNHjpxXUZYVn+Js2064FtXa2iqPxxM7Kisrz+u9ASCX5eLkSSDTUu55ueOOO3TzzTdP22bRokWzKsbr9Uqa7IHx+f5v/GxoaCihNyZq27Zt2rJlS+w8HA4TYADkrejkyab2HllS3MTdbE2eBDIt5fBSWlqq0tJSJ2qR3++X1+vVwYMHddVVV0maXLH00ksv6YEHHkh6j8vlksvlcqQeAMhF0cmTn9znxcs+L5gjHJ3zMjg4qOHhYQ0ODioSiai3t1eSdOmll+rTn/60JOnKK69Ua2urbrzxRlmWpc2bN+v+++/XZZddpssuu0z333+/FixYoFtuucXJUgHAKLk0eRLINEfDy7333qs9e/bEzqO9KS+++KJWrlwpSTp27JhCoVCszV133aV///vf2rRpkz744AMtW7ZMBw4cUFFRkZOlAoBxcmXyJJBplm3bebWTUTgclsfjUSgUUnFxcbbLAQAAM5DK9zdPlQYAAEYhvAAAAKMQXgAAgFEILwAAwCiEFwAAYJScerYRAACpikzY7HczxxBeAADG6uwLJOw07GOn4bzHsBEAwEidfQE1tffEBRdJCoZG1dTeo86+QJYqg9MILwAA40QmbLV09CvZLqvRay0d/YpM5NU+rPhfhBcAgHG6B4YTelw+zpYUCI2qe2A4c0UhYwgvAADjDI1MHVxm0w5mIbwAAIxTVuROazuYhfACADBOrb9EPo9bUy2ItjS56qjWX5LJspAhhBcAgHEKCyw1N1ZJUkKAiZ43N1ax30ueIrwAAIzUUO1T27ql8nrih4a8Hrfa1i1ln5c8xiZ1AABjNVT7tLrKyw67cwzhBQBgtMICS3WLF2a7DGQQw0YAAMAohBcAAGAUwgsAADAK4QUAABiF8AIAAIxCeAEAAEYhvAAAAKMQXgAAgFEILwAAwCiEFwAAYBTCCwAAMArhBQAAGIXwAgAAjEJ4AQAARiG8AAAAoxBeAACAUQgvAADAKIQXAABgFMILAAAwCuEFAAAYhfACAACM4mh4ue+++7RixQotWLBAF1544YzuufXWW2VZVtyxfPlyJ8sEAAAGcTS8jI+Pa+3atWpqakrpvoaGBgUCgdixf/9+hyoEAACmmefkH97S0iJJ2r17d0r3uVwueb1eByoCAACmy8k5L4cOHVJZWZkuv/xybdiwQUNDQ1O2HRsbUzgcjjsAAED+yrnwsmbNGj333HP6/e9/r4cfflivvfaavvKVr2hsbCxp+9bWVnk8nthRWVmZ4YoBAEAmpRxetm/fnjCh9pPHkSNHZl3QTTfdpK997Wuqrq5WY2Ojfve73+mvf/2rXnjhhaTtt23bplAoFDtOnDgx6/cGAAC5L+U5L3fccYduvvnmadssWrRotvUk8Pl8uuSSS/S3v/0t6esul0sulytt7wcAAHJbyuGltLRUpaWlTtSS1JkzZ3TixAn5fL6MvScAAMhdjs55GRwcVG9vrwYHBxWJRNTb26ve3l6dPXs21ubKK6/Uvn37JElnz57V1q1b1dXVpXfffVeHDh1SY2OjSktLdeONNzpZKgAAMISjS6Xvvfde7dmzJ3Z+1VVXSZJefPFFrVy5UpJ07NgxhUIhSVJhYaH+8pe/6Nlnn9WHH34on8+nVatWae/evSoqKnKyVAAAYAjLtm0720WkUzgclsfjUSgUUnFxcbbLAQAAM5DK93fOLZUGAACYDuEFAAAYhfACAACMQngBAABGIbwAAACjEF4AAIBRCC8AAMAohBcAAGAUwgsAADAK4QUAABiF8AIAAIxCeAEAAEYhvAAAAKMQXgAAgFEILwAAwCiEFwAAYBTCCwAAMArhBQAAGIXwAgAAjEJ4AQAARiG8AAAAoxBeAACAUQgvAADAKIQXAABgFMILAAAwCuEFAAAYhfACAACMQngBAABGIbwAAACjEF4AAIBRCC8AAMAohBcAAGAUwgsAADAK4QUAABiF8AIAAIxCeAEAAEYhvAAAAKM4Fl7effdd3XbbbfL7/Zo/f74WL16s5uZmjY+PT3ufbdvavn27KioqNH/+fK1cuVJvvvmmU2UCAADDOBZe3nrrLU1MTOiJJ57Qm2++qUcffVS7du3S3XffPe19Dz74oB555BHt2LFDr732mrxer1avXq2RkRGnSgUAAAaxbNu2M/VmP/nJT9TW1qZ33nkn6eu2bauiokKbN2/WD3/4Q0nS2NiYysvL9cADD+j73//+Od8jHA7L4/EoFAqpuLg4rfUDAABnpPL9ndE5L6FQSCUlJVO+PjAwoGAwqPr6+tg1l8ulL3/5yzp8+HAmSgQAADluXqbe6Pjx4/rZz36mhx9+eMo2wWBQklReXh53vby8XO+9917Se8bGxjQ2NhY7D4fDaagWAADkqpR7XrZv3y7LsqY9jhw5EnfPqVOn1NDQoLVr1+r2228/53tYlhV3btt2wrWo1tZWeTye2FFZWZnqjwQAAAyS8pyX06dP6/Tp09O2WbRokdxut6TJ4LJq1SotW7ZMu3fvVkHB1HnpnXfe0eLFi9XT06Orrroqdv3666/XhRdeqD179iTck6znpbKykjkvAAAYJJU5LykPG5WWlqq0tHRGbU+ePKlVq1appqZGzzzzzLTBRZL8fr+8Xq8OHjwYCy/j4+N66aWX9MADDyS9x+VyyeVypfZDAAAAYzk2YffUqVNauXKlKisr9dBDD+n9999XMBiMzWuJuvLKK7Vv3z5Jk8NFmzdv1v333699+/apr69Pt956qxYsWKBbbrnFqVIBAIBBHJuwe+DAAb399tt6++23ddFFF8W99vGRqmPHjikUCsXO77rrLv373//Wpk2b9MEHH2jZsmU6cOCAioqKnCoVAAAYJKP7vGQC+7wAAGCenN3nBQAA4HwRXgAAgFEILwAAwCiEFwAAYBTCCwAAMArhBQAAGIXwAgAAjEJ4AQAARiG8AAAAoxBeAACAUQgvAADAKIQXAABgFMILAAAwCuEFAAAYhfACAACMMi/bBQCAqSITtroHhjU0MqqyIrdq/SUqLLCyXRaQ9wgvADALnX0BtXT0KxAajV3zedxqbqxSQ7Uvi5UB+Y9hIwBIUWdfQE3tPXHBRZKCoVE1tfeosy+QpcqAuYHwAgApiEzYaunol53ktei1lo5+RSaStQCQDoQXAEhB98BwQo/Lx9mSAqFRdQ8MZ64oYI4hvABACoZGpg4us2kHIHWEFwBIQVmRO63tAKSO8AIAKaj1l8jncWuqBdGWJlcd1fpLMlkWMKcQXgAgBYUFlpobqyQpIcBEz5sbq9jvBXAQ4QUAUtRQ7VPbuqXyeuKHhrwet9rWLWWfF8BhbFIHALPQUO3T6iovO+wCWUB4AYBZKiywVLd4YbbLAOYcho0AAIBRCC8AAMAohBcAAGAUwgsAADAK4QUAABiF8AIAAIxCeAEAAEYhvAAAAKMQXgAAgFHybodd27YlSeFwOMuVAACAmYp+b0e/x6eTd+FlZGREklRZWZnlSgAAQKpGRkbk8XimbWPZM4k4BpmYmNCpU6dUVFQky5q7D0gLh8OqrKzUiRMnVFxcnO1yMAN8ZubhMzMPn1nusm1bIyMjqqioUEHB9LNa8q7npaCgQBdddFG2y8gZxcXF/AU1DJ+ZefjMzMNnlpvO1eMSxYRdAABgFMILAAAwCuElT7lcLjU3N8vlcmW7FMwQn5l5+MzMw2eWH/Juwi4AAMhv9LwAAACjEF4AAIBRCC8AAMAohBcAAGAUwkuee/fdd3XbbbfJ7/dr/vz5Wrx4sZqbmzU+Pp7t0jCN++67TytWrNCCBQt04YUXZrscJLFz5075/X653W7V1NTolVdeyXZJmMbLL7+sxsZGVVRUyLIs/frXv852STgPhJc899Zbb2liYkJPPPGE3nzzTT366KPatWuX7r777myXhmmMj49r7dq1ampqynYpSGLv3r3avHmz7rnnHr3xxhu65pprtGbNGg0ODma7NEzhn//8p77whS9ox44d2S4FacBS6TnoJz/5idra2vTOO+9kuxScw+7du7V582Z9+OGH2S4FH7Ns2TItXbpUbW1tsWtLlizRDTfcoNbW1ixWhpmwLEv79u3TDTfckO1SMEv0vMxBoVBIJSUl2S4DMNL4+Lhef/111dfXx12vr6/X4cOHs1QVMLcQXuaY48eP62c/+5k2btyY7VIAI50+fVqRSETl5eVx18vLyxUMBrNUFTC3EF4MtX37dlmWNe1x5MiRuHtOnTqlhoYGrV27VrfffnuWKp+7ZvOZIXdZlhV3btt2wjUAzpiX7QIwO3fccYduvvnmadssWrQo9t+nTp3SqlWrVFdXpyeffNLh6pBMqp8ZclNpaakKCwsTelmGhoYSemMAOIPwYqjS0lKVlpbOqO3Jkye1atUq1dTU6JlnnlFBAR1u2ZDKZ4bcdcEFF6impkYHDx7UjTfeGLt+8OBBXX/99VmsDJg7CC957tSpU1q5cqUuvvhiPfTQQ3r//fdjr3m93ixWhukMDg5qeHhYg4ODikQi6u3tlSRdeuml+vSnP53d4qAtW7Zo/fr1uvrqq2O9mYODg8wly2Fnz57V22+/HTsfGBhQb2+vSkpKdPHFF2exMswGS6Xz3O7du/Xd73436Wt89Lnr1ltv1Z49exKuv/jii1q5cmXmC0KCnTt36sEHH1QgEFB1dbUeffRRfelLX8p2WZjCoUOHtGrVqoTr3/nOd7R79+7MF4TzQngBAABGYfIDAAAwCuEFAAAYhfACAACMQngBAABGIbwAAACjEF4AAIBRCC8AAMAohBcAAGAUwgsAADAK4QUAABiF8AIAAIxCeAEAAEb5/4+xGo5fOc4QAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x[:,0],x[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a04df9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[]\n",
    "for i in range(x.shape[0]):\n",
    "    if(x[i][0]<0.5 and x[i][0]>-0.5):\n",
    "        y.append(0)\n",
    "    else:\n",
    "        y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0507fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(y)\n",
    "y=y.astype(\"float32\")\n",
    "y=torch.tensor(y)\n",
    "x=x.astype(\"float32\")\n",
    "x=torch.tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "804adc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "        0., 1.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b017d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nntree3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.t1=nn.Parameter(torch.randn((1,2)))\n",
    "        self.b1=nn.Parameter(torch.randn(1))\n",
    "        self.t11=nn.Parameter(torch.randn((1,2)))\n",
    "        self.b11=nn.Parameter(torch.randn(1))\n",
    "        self.t12=nn.Parameter(torch.randn((1,2)))\n",
    "        self.b12=nn.Parameter(torch.randn(1))\n",
    "        self.relu=nn.ReLU()\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "    def forward(self,x):\n",
    "        o=self.t1@x+self.b1\n",
    "        o1=torch.max(torch.tensor(0.01),self.relu(o))\n",
    "        o2=torch.max(torch.tensor(0.01),self.relu(-o))\n",
    "        o1=o1*(self.t11@x+self.b11)\n",
    "        o2=o2*(self.t12@x+self.b12)\n",
    "        o11=torch.max(torch.tensor(0.01),self.relu(o1))\n",
    "        o12=torch.max(torch.tensor(0.01),self.relu(-o1))\n",
    "        o21=torch.max(torch.tensor(0.01),self.relu(o2))\n",
    "        o22=torch.max(torch.tensor(0.01),self.relu(-o2))\n",
    "        p1=o11+o21\n",
    "        p2=o12+o22 \n",
    "        f=torch.cat((p1,p2),0)\n",
    "        f=self.softmax(f.reshape(1,-1))\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4c1ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=nntree3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1eaf406c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion=nn.BCELoss()\n",
    "optimizer=torch.optim.Adam(model2.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af58adb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=model2(x[0].reshape((2,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7d8c10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18.9019, grad_fn=<AddBackward0>)\n",
      "tensor(13.4047, grad_fn=<AddBackward0>)\n",
      "tensor(10.2946, grad_fn=<AddBackward0>)\n",
      "tensor(8.8830, grad_fn=<AddBackward0>)\n",
      "tensor(8.2447, grad_fn=<AddBackward0>)\n",
      "tensor(7.9094, grad_fn=<AddBackward0>)\n",
      "tensor(7.6168, grad_fn=<AddBackward0>)\n",
      "tensor(7.3168, grad_fn=<AddBackward0>)\n",
      "tensor(7.0124, grad_fn=<AddBackward0>)\n",
      "tensor(6.8338, grad_fn=<AddBackward0>)\n",
      "tensor(6.7005, grad_fn=<AddBackward0>)\n",
      "tensor(6.5958, grad_fn=<AddBackward0>)\n",
      "tensor(6.5879, grad_fn=<AddBackward0>)\n",
      "tensor(6.6036, grad_fn=<AddBackward0>)\n",
      "tensor(6.6087, grad_fn=<AddBackward0>)\n",
      "tensor(6.5932, grad_fn=<AddBackward0>)\n",
      "tensor(6.5525, grad_fn=<AddBackward0>)\n",
      "tensor(6.4870, grad_fn=<AddBackward0>)\n",
      "tensor(6.4023, grad_fn=<AddBackward0>)\n",
      "tensor(6.3033, grad_fn=<AddBackward0>)\n",
      "tensor(6.2375, grad_fn=<AddBackward0>)\n",
      "tensor(6.2136, grad_fn=<AddBackward0>)\n",
      "tensor(6.1925, grad_fn=<AddBackward0>)\n",
      "tensor(6.1708, grad_fn=<AddBackward0>)\n",
      "tensor(6.1453, grad_fn=<AddBackward0>)\n",
      "tensor(6.1243, grad_fn=<AddBackward0>)\n",
      "tensor(6.0898, grad_fn=<AddBackward0>)\n",
      "tensor(6.0342, grad_fn=<AddBackward0>)\n",
      "tensor(5.9628, grad_fn=<AddBackward0>)\n",
      "tensor(5.9027, grad_fn=<AddBackward0>)\n",
      "tensor(5.8472, grad_fn=<AddBackward0>)\n",
      "tensor(5.7939, grad_fn=<AddBackward0>)\n",
      "tensor(5.7414, grad_fn=<AddBackward0>)\n",
      "tensor(5.6984, grad_fn=<AddBackward0>)\n",
      "tensor(5.6459, grad_fn=<AddBackward0>)\n",
      "tensor(5.5954, grad_fn=<AddBackward0>)\n",
      "tensor(5.5375, grad_fn=<AddBackward0>)\n",
      "tensor(5.4770, grad_fn=<AddBackward0>)\n",
      "tensor(5.4261, grad_fn=<AddBackward0>)\n",
      "tensor(5.4057, grad_fn=<AddBackward0>)\n",
      "tensor(5.3800, grad_fn=<AddBackward0>)\n",
      "tensor(5.3351, grad_fn=<AddBackward0>)\n",
      "tensor(5.2744, grad_fn=<AddBackward0>)\n",
      "tensor(5.2212, grad_fn=<AddBackward0>)\n",
      "tensor(5.1909, grad_fn=<AddBackward0>)\n",
      "tensor(5.1548, grad_fn=<AddBackward0>)\n",
      "tensor(5.1094, grad_fn=<AddBackward0>)\n",
      "tensor(5.0649, grad_fn=<AddBackward0>)\n",
      "tensor(5.0345, grad_fn=<AddBackward0>)\n",
      "tensor(5.0061, grad_fn=<AddBackward0>)\n",
      "tensor(4.9733, grad_fn=<AddBackward0>)\n",
      "tensor(4.9367, grad_fn=<AddBackward0>)\n",
      "tensor(4.8974, grad_fn=<AddBackward0>)\n",
      "tensor(4.8564, grad_fn=<AddBackward0>)\n",
      "tensor(4.8146, grad_fn=<AddBackward0>)\n",
      "tensor(4.7750, grad_fn=<AddBackward0>)\n",
      "tensor(4.7348, grad_fn=<AddBackward0>)\n",
      "tensor(4.6917, grad_fn=<AddBackward0>)\n",
      "tensor(4.6522, grad_fn=<AddBackward0>)\n",
      "tensor(4.6128, grad_fn=<AddBackward0>)\n",
      "tensor(4.5731, grad_fn=<AddBackward0>)\n",
      "tensor(4.5329, grad_fn=<AddBackward0>)\n",
      "tensor(4.4966, grad_fn=<AddBackward0>)\n",
      "tensor(4.4659, grad_fn=<AddBackward0>)\n",
      "tensor(4.4218, grad_fn=<AddBackward0>)\n",
      "tensor(4.3829, grad_fn=<AddBackward0>)\n",
      "tensor(4.3433, grad_fn=<AddBackward0>)\n",
      "tensor(4.3061, grad_fn=<AddBackward0>)\n",
      "tensor(4.2685, grad_fn=<AddBackward0>)\n",
      "tensor(4.2305, grad_fn=<AddBackward0>)\n",
      "tensor(4.1924, grad_fn=<AddBackward0>)\n",
      "tensor(4.1542, grad_fn=<AddBackward0>)\n",
      "tensor(4.1158, grad_fn=<AddBackward0>)\n",
      "tensor(4.0789, grad_fn=<AddBackward0>)\n",
      "tensor(4.0385, grad_fn=<AddBackward0>)\n",
      "tensor(3.9997, grad_fn=<AddBackward0>)\n",
      "tensor(3.9608, grad_fn=<AddBackward0>)\n",
      "tensor(3.9225, grad_fn=<AddBackward0>)\n",
      "tensor(3.8843, grad_fn=<AddBackward0>)\n",
      "tensor(3.8463, grad_fn=<AddBackward0>)\n",
      "tensor(3.8083, grad_fn=<AddBackward0>)\n",
      "tensor(3.7704, grad_fn=<AddBackward0>)\n",
      "tensor(3.7325, grad_fn=<AddBackward0>)\n",
      "tensor(3.6948, grad_fn=<AddBackward0>)\n",
      "tensor(3.6574, grad_fn=<AddBackward0>)\n",
      "tensor(3.6200, grad_fn=<AddBackward0>)\n",
      "tensor(3.5831, grad_fn=<AddBackward0>)\n",
      "tensor(3.5467, grad_fn=<AddBackward0>)\n",
      "tensor(3.5108, grad_fn=<AddBackward0>)\n",
      "tensor(3.4770, grad_fn=<AddBackward0>)\n",
      "tensor(3.4410, grad_fn=<AddBackward0>)\n",
      "tensor(3.4071, grad_fn=<AddBackward0>)\n",
      "tensor(3.3735, grad_fn=<AddBackward0>)\n",
      "tensor(3.3398, grad_fn=<AddBackward0>)\n",
      "tensor(3.3068, grad_fn=<AddBackward0>)\n",
      "tensor(3.2757, grad_fn=<AddBackward0>)\n",
      "tensor(3.2443, grad_fn=<AddBackward0>)\n",
      "tensor(3.2072, grad_fn=<AddBackward0>)\n",
      "tensor(3.1728, grad_fn=<AddBackward0>)\n",
      "tensor(3.1428, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "num_epochs=100\n",
    "epoch=0\n",
    "for epoch in range(num_epochs):\n",
    "    loss=0\n",
    "    for i in range(20):\n",
    "        output=model2(x[i].reshape((2,1)))\n",
    "        loss+=criterion(output[0][0],y[i])\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d72fc2b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 tensor([[3.6601, 1.5484]])\n",
      "b1 tensor([-1.0240])\n",
      "t11 tensor([[ 4.5103, -2.6238]])\n",
      "b11 tensor([0.3006])\n",
      "t12 tensor([[-1.7381,  1.1924]])\n",
      "b12 tensor([-0.8463])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model2.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e96a912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in range(20):\n",
    "    c=0\n",
    "    if(model2(x[i].reshape((2,1)))[0][0]>0.5):\n",
    "        c=1\n",
    "    else:\n",
    "        c=0\n",
    "    if(y[i]==c):\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cad8b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eef14a",
   "metadata": {},
   "source": [
    "## General n depth tree for multidimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5311fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nntree_gen(nn.Module):\n",
    "    def __init__(self,dim,depth):\n",
    "        super().__init__()\n",
    "        self.dim=dim\n",
    "        self.depth = depth\n",
    "        self.t= nn.ParameterList([])\n",
    "        self.b= nn.ParameterList([])\n",
    "        for i in range(self.depth):\n",
    "            for j in range(2**i):\n",
    "                t1=nn.Parameter(torch.randn(1,dim))\n",
    "                self.t.append(t1)\n",
    "                b1=nn.Parameter(torch.randn(1,1))\n",
    "                self.b.append(b1)\n",
    "        self.relu=nn.ELU(alpha=1.0, inplace=False)\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "#         self.t=np.array(self.t)\n",
    "#         self.b=np.array(self.b)\n",
    "#         self.t=nn.Parameter(self.t)\n",
    "#         self.b=nn.Parameter(self.b)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        curr_o=[]\n",
    "        for i in range(self.depth):\n",
    "            if(i==0):\n",
    "                o=self.t[2**(i)-1]@x+self.b[2**(i)-1]\n",
    "                curr_o.append(torch.max(torch.tensor(0.0),self.relu(o)))\n",
    "                curr_o.append(torch.max(torch.tensor(0.0),self.relu(-o)))\n",
    "            else:\n",
    "                curr1_o=[]\n",
    "                for j in range(2**(i)):\n",
    "                    o=curr_o[j]*(self.t[2**(i)-1+j]@x+self.b[2**(i)-1+j])\n",
    "                    o=o*(0.1)\n",
    "                    curr1_o.append(torch.max(torch.tensor(0.0),self.relu(o)))\n",
    "                    curr1_o.append(torch.max(torch.tensor(0.0),self.relu(-o)))\n",
    "                    \n",
    "                curr_o=curr1_o\n",
    "        p1=0\n",
    "        p2=0\n",
    "#         print(curr_o)\n",
    "        for i in range(len(curr_o)):\n",
    "            if(i%2==0):\n",
    "                p1+=curr_o[i]\n",
    "                \n",
    "            else:\n",
    "                p2+=curr_o[i]\n",
    "                    \n",
    "                    \n",
    "        f=torch.cat((p1,p2),0)\n",
    "        f=self.softmax(f.reshape(1,-1))\n",
    "        return f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a004ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=nntree_gen(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aeb7a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.BCELoss()\n",
    "optimizer=torch.optim.Adam(model3.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62feb63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.8875, grad_fn=<AddBackward0>)\n",
      "tensor(13.8641, grad_fn=<AddBackward0>)\n",
      "tensor(13.8407, grad_fn=<AddBackward0>)\n",
      "tensor(13.8095, grad_fn=<AddBackward0>)\n",
      "tensor(13.7653, grad_fn=<AddBackward0>)\n",
      "tensor(13.7031, grad_fn=<AddBackward0>)\n",
      "tensor(13.6186, grad_fn=<AddBackward0>)\n",
      "tensor(13.5082, grad_fn=<AddBackward0>)\n",
      "tensor(13.3696, grad_fn=<AddBackward0>)\n",
      "tensor(13.2026, grad_fn=<AddBackward0>)\n",
      "tensor(13.0097, grad_fn=<AddBackward0>)\n",
      "tensor(12.7975, grad_fn=<AddBackward0>)\n",
      "tensor(12.5734, grad_fn=<AddBackward0>)\n",
      "tensor(12.3441, grad_fn=<AddBackward0>)\n",
      "tensor(12.1140, grad_fn=<AddBackward0>)\n",
      "tensor(11.8858, grad_fn=<AddBackward0>)\n",
      "tensor(11.6585, grad_fn=<AddBackward0>)\n",
      "tensor(11.4339, grad_fn=<AddBackward0>)\n",
      "tensor(11.2166, grad_fn=<AddBackward0>)\n",
      "tensor(11.0114, grad_fn=<AddBackward0>)\n",
      "tensor(10.8177, grad_fn=<AddBackward0>)\n",
      "tensor(10.6340, grad_fn=<AddBackward0>)\n",
      "tensor(10.4572, grad_fn=<AddBackward0>)\n",
      "tensor(10.2837, grad_fn=<AddBackward0>)\n",
      "tensor(10.1101, grad_fn=<AddBackward0>)\n",
      "tensor(9.9326, grad_fn=<AddBackward0>)\n",
      "tensor(9.7472, grad_fn=<AddBackward0>)\n",
      "tensor(9.5515, grad_fn=<AddBackward0>)\n",
      "tensor(9.3408, grad_fn=<AddBackward0>)\n",
      "tensor(9.1132, grad_fn=<AddBackward0>)\n",
      "tensor(8.8693, grad_fn=<AddBackward0>)\n",
      "tensor(8.6123, grad_fn=<AddBackward0>)\n",
      "tensor(8.3481, grad_fn=<AddBackward0>)\n",
      "tensor(8.0983, grad_fn=<AddBackward0>)\n",
      "tensor(7.8666, grad_fn=<AddBackward0>)\n",
      "tensor(7.6584, grad_fn=<AddBackward0>)\n",
      "tensor(7.4788, grad_fn=<AddBackward0>)\n",
      "tensor(7.3290, grad_fn=<AddBackward0>)\n",
      "tensor(7.2078, grad_fn=<AddBackward0>)\n",
      "tensor(7.1305, grad_fn=<AddBackward0>)\n",
      "tensor(7.0733, grad_fn=<AddBackward0>)\n",
      "tensor(7.0305, grad_fn=<AddBackward0>)\n",
      "tensor(6.9967, grad_fn=<AddBackward0>)\n",
      "tensor(6.9658, grad_fn=<AddBackward0>)\n",
      "tensor(6.9325, grad_fn=<AddBackward0>)\n",
      "tensor(6.8925, grad_fn=<AddBackward0>)\n",
      "tensor(6.8436, grad_fn=<AddBackward0>)\n",
      "tensor(6.7849, grad_fn=<AddBackward0>)\n",
      "tensor(6.7168, grad_fn=<AddBackward0>)\n",
      "tensor(6.6404, grad_fn=<AddBackward0>)\n",
      "tensor(6.5604, grad_fn=<AddBackward0>)\n",
      "tensor(6.4844, grad_fn=<AddBackward0>)\n",
      "tensor(6.4492, grad_fn=<AddBackward0>)\n",
      "tensor(6.4423, grad_fn=<AddBackward0>)\n",
      "tensor(6.4316, grad_fn=<AddBackward0>)\n",
      "tensor(6.4171, grad_fn=<AddBackward0>)\n",
      "tensor(6.3989, grad_fn=<AddBackward0>)\n",
      "tensor(6.3777, grad_fn=<AddBackward0>)\n",
      "tensor(6.3542, grad_fn=<AddBackward0>)\n",
      "tensor(6.3291, grad_fn=<AddBackward0>)\n",
      "tensor(6.3029, grad_fn=<AddBackward0>)\n",
      "tensor(6.2759, grad_fn=<AddBackward0>)\n",
      "tensor(6.2479, grad_fn=<AddBackward0>)\n",
      "tensor(6.2184, grad_fn=<AddBackward0>)\n",
      "tensor(6.1865, grad_fn=<AddBackward0>)\n",
      "tensor(6.1512, grad_fn=<AddBackward0>)\n",
      "tensor(6.1113, grad_fn=<AddBackward0>)\n",
      "tensor(6.0703, grad_fn=<AddBackward0>)\n",
      "tensor(6.0234, grad_fn=<AddBackward0>)\n",
      "tensor(5.9702, grad_fn=<AddBackward0>)\n",
      "tensor(5.9047, grad_fn=<AddBackward0>)\n",
      "tensor(5.8318, grad_fn=<AddBackward0>)\n",
      "tensor(5.7558, grad_fn=<AddBackward0>)\n",
      "tensor(5.6738, grad_fn=<AddBackward0>)\n",
      "tensor(5.5826, grad_fn=<AddBackward0>)\n",
      "tensor(5.4878, grad_fn=<AddBackward0>)\n",
      "tensor(5.3962, grad_fn=<AddBackward0>)\n",
      "tensor(5.3089, grad_fn=<AddBackward0>)\n",
      "tensor(5.2287, grad_fn=<AddBackward0>)\n",
      "tensor(5.1562, grad_fn=<AddBackward0>)\n",
      "tensor(5.0902, grad_fn=<AddBackward0>)\n",
      "tensor(5.0282, grad_fn=<AddBackward0>)\n",
      "tensor(4.9671, grad_fn=<AddBackward0>)\n",
      "tensor(4.9047, grad_fn=<AddBackward0>)\n",
      "tensor(4.8390, grad_fn=<AddBackward0>)\n",
      "tensor(4.7729, grad_fn=<AddBackward0>)\n",
      "tensor(4.7036, grad_fn=<AddBackward0>)\n",
      "tensor(4.6285, grad_fn=<AddBackward0>)\n",
      "tensor(4.5484, grad_fn=<AddBackward0>)\n",
      "tensor(4.4639, grad_fn=<AddBackward0>)\n",
      "tensor(4.3795, grad_fn=<AddBackward0>)\n",
      "tensor(4.2948, grad_fn=<AddBackward0>)\n",
      "tensor(4.2079, grad_fn=<AddBackward0>)\n",
      "tensor(4.1196, grad_fn=<AddBackward0>)\n",
      "tensor(4.0370, grad_fn=<AddBackward0>)\n",
      "tensor(3.9537, grad_fn=<AddBackward0>)\n",
      "tensor(3.8688, grad_fn=<AddBackward0>)\n",
      "tensor(3.7832, grad_fn=<AddBackward0>)\n",
      "tensor(3.6994, grad_fn=<AddBackward0>)\n",
      "tensor(3.6196, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "num_epochs=100\n",
    "epoch=0\n",
    "for epoch in range(num_epochs):\n",
    "    loss=0\n",
    "    for i in range(20):\n",
    "        output=model3(x[i].reshape((2,1)))\n",
    "        loss+=criterion(output[0][0],y[i])\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "08331fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in range(20):\n",
    "    c=0\n",
    "    if(model3(x[i].reshape((2,1)))[0][0]>0.5):\n",
    "        c=1\n",
    "    else:\n",
    "        c=0\n",
    "    if(y[i]==c):\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ae23f806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cecaac4",
   "metadata": {},
   "source": [
    "### Running on Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6250f633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris() \n",
    "X_train = iris.data \n",
    "y_train = iris.target \n",
    "names = iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "94d865b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train[:100,:]\n",
    "y_train=y_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "22701ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "61726bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=nntree_gen(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28d90cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.BCELoss()\n",
    "optimizer=torch.optim.Adam(model3.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57dacc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=time.time()\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X=X_train, y=y_train)\n",
    "b=time.time()\n",
    "clf.feature_importances_ # [ 1.,  0.,  0.]\n",
    "clf.score(X=X_test, y=y_test) # 1.0\n",
    "clf.predict(X_test) # array([0, 0, 0, 3, 1, 0, 3, 0, 0, 3, 2, 2, 1, 3, 2, 0, 2, 0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0fb726bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00099945068359375"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "89d86b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b4ca6002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_ # [ 1.,  0.,  0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "01d423f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=torch.tensor(X_train.astype(\"float32\"))\n",
    "y_train=torch.tensor(y_train.astype(\"float32\"))\n",
    "X_test=torch.tensor(X_test.astype(\"float32\"))\n",
    "y_test=torch.tensor(y_test.astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "05a3450d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5336\\3050072171.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5336\\2842973991.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m                 \u001b[0mcurr_o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mcurr_o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    755\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "num_epochs=20\n",
    "epoch=0\n",
    "for epoch in range(num_epochs):\n",
    "    loss=0\n",
    "    for i in range(80):\n",
    "        output=model3(X_train[i].detach().numpy().reshape((4,1)))\n",
    "        loss+=criterion(output[0][0], y_train[i])\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a1dde7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(20):\n",
    "    c=0\n",
    "    \n",
    "    if(model3(X_test[i].reshape((4,1)))[0][0]>0.5):\n",
    "        c=1\n",
    "    else:\n",
    "        c=0\n",
    "    if(y_test[i]==c):\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eddb24",
   "metadata": {},
   "source": [
    "### On higher dimensional Dataset (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f071ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nntree_gen(nn.Module):\n",
    "    def __init__(self,dim,depth):\n",
    "        super().__init__()\n",
    "        self.dim=dim\n",
    "        self.depth = depth\n",
    "        self.t= nn.ParameterList([])\n",
    "        self.b= nn.ParameterList([])\n",
    "        for i in range(self.depth):\n",
    "            for j in range(2**i):\n",
    "                t1=nn.Parameter(torch.randn(1,dim))\n",
    "                self.t.append(t1)\n",
    "                b1=nn.Parameter(torch.randn(1,1))\n",
    "                self.b.append(b1)\n",
    "        self.relu=nn.ELU(alpha=1.0, inplace=False)\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        curr_o=[]\n",
    "        for i in range(self.depth):\n",
    "            if(len(curr_o)==0):\n",
    "                o=self.t[2**(i)-1]@x+self.b[2**(i)-1]\n",
    "                curr_o.append(torch.max(torch.tensor(0.0),self.relu(o)))\n",
    "                curr_o.append(torch.max(torch.tensor(0.0),self.relu(-o)))\n",
    "            \n",
    "            else:\n",
    "                curr1_o=[]\n",
    "                for j in range(2**(i)):\n",
    "                    o=curr_o[j]*(torch.mm(self.t[2**(i)-1+j],x)+self.b[2**(i)-1+j])\n",
    "                    o=o*(0.1)\n",
    "                    curr1_o.append(torch.max(torch.tensor(0.0),self.relu(o)))\n",
    "                    curr1_o.append(torch.max(torch.tensor(0.0),self.relu(-o)))\n",
    "                    \n",
    "                curr_o=curr1_o\n",
    "        p1=0\n",
    "        p2=0\n",
    "        for i in range(len(curr_o)):\n",
    "            if(i%2==0):\n",
    "                p1+=curr_o[i]\n",
    "                \n",
    "            else:\n",
    "                p2+=curr_o[i]\n",
    "        f=torch.stack((p1,p2),0).reshape(2,x.shape[1])\n",
    "        f=self.softmax(f.T)\n",
    "        return f        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b382e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6df2bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"bank_dataset - Copy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "98b217e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>73</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>46</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>56</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>74</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41188 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          job  marital            education  default housing loan  \\\n",
       "0       56    housemaid  married             basic.4y       no      no   no   \n",
       "1       57     services  married          high.school  unknown      no   no   \n",
       "2       37     services  married          high.school       no     yes   no   \n",
       "3       40       admin.  married             basic.6y       no      no   no   \n",
       "4       56     services  married          high.school       no      no  yes   \n",
       "...    ...          ...      ...                  ...      ...     ...  ...   \n",
       "41183   73      retired  married  professional.course       no     yes   no   \n",
       "41184   46  blue-collar  married  professional.course       no      no   no   \n",
       "41185   56      retired  married    university.degree       no     yes   no   \n",
       "41186   44   technician  married  professional.course       no      no   no   \n",
       "41187   74      retired  married  professional.course       no     yes   no   \n",
       "\n",
       "         contact month day_of_week  ...  campaign  pdays  previous  \\\n",
       "0      telephone   may         mon  ...         1    999         0   \n",
       "1      telephone   may         mon  ...         1    999         0   \n",
       "2      telephone   may         mon  ...         1    999         0   \n",
       "3      telephone   may         mon  ...         1    999         0   \n",
       "4      telephone   may         mon  ...         1    999         0   \n",
       "...          ...   ...         ...  ...       ...    ...       ...   \n",
       "41183   cellular   nov         fri  ...         1    999         0   \n",
       "41184   cellular   nov         fri  ...         1    999         0   \n",
       "41185   cellular   nov         fri  ...         2    999         0   \n",
       "41186   cellular   nov         fri  ...         1    999         0   \n",
       "41187   cellular   nov         fri  ...         3    999         1   \n",
       "\n",
       "          poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "1      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "2      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "3      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "4      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "...            ...          ...             ...            ...        ...   \n",
       "41183  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41184  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41185  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41186  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41187      failure         -1.1          94.767          -50.8      1.028   \n",
       "\n",
       "       nr.employed    y  \n",
       "0           5191.0   no  \n",
       "1           5191.0   no  \n",
       "2           5191.0   no  \n",
       "3           5191.0   no  \n",
       "4           5191.0   no  \n",
       "...            ...  ...  \n",
       "41183       4963.6  yes  \n",
       "41184       4963.6   no  \n",
       "41185       4963.6   no  \n",
       "41186       4963.6  yes  \n",
       "41187       4963.6   no  \n",
       "\n",
       "[41188 rows x 21 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d5c88c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job'] = df['job'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9a47a2b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([93.994, 94.465, 93.918, 93.444, 93.798, 93.2  , 92.756, 92.843,\n",
       "       93.075, 92.893, 92.963, 92.469, 92.201, 92.379, 92.431, 92.649,\n",
       "       92.713, 93.369, 93.749, 93.876, 94.055, 94.215, 94.027, 94.199,\n",
       "       94.601, 94.767])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cons.price.idx'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0dc85734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2bdc5f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Categorical_variables=['job','marital','contact', 'poutcome','education', 'default', 'housing', 'loan', 'month',\n",
    "       'day_of_week','y']\n",
    "\n",
    "\n",
    "feature_scale=[feature for feature in df.columns if feature not in Categorical_variables]\n",
    "\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(df[feature_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fdc5fd36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>contact</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>telephone</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1.533034</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>married</td>\n",
       "      <td>telephone</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1.628993</td>\n",
       "      <td>-0.421501</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>married</td>\n",
       "      <td>telephone</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290186</td>\n",
       "      <td>-0.124520</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>married</td>\n",
       "      <td>telephone</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002309</td>\n",
       "      <td>-0.413787</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>married</td>\n",
       "      <td>telephone</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1.533034</td>\n",
       "      <td>0.187888</td>\n",
       "      <td>-0.565922</td>\n",
       "      <td>0.195414</td>\n",
       "      <td>-0.349494</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.886447</td>\n",
       "      <td>0.71246</td>\n",
       "      <td>0.33168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   job  marital    contact     poutcome    education  default housing loan  \\\n",
       "0    3  married  telephone  nonexistent     basic.4y       no      no   no   \n",
       "1    7  married  telephone  nonexistent  high.school  unknown      no   no   \n",
       "2    7  married  telephone  nonexistent  high.school       no     yes   no   \n",
       "3    0  married  telephone  nonexistent     basic.6y       no      no   no   \n",
       "4    7  married  telephone  nonexistent  high.school       no      no  yes   \n",
       "\n",
       "  month day_of_week  ...       age  duration  campaign     pdays  previous  \\\n",
       "0   may         mon  ...  1.533034  0.010471 -0.565922  0.195414 -0.349494   \n",
       "1   may         mon  ...  1.628993 -0.421501 -0.565922  0.195414 -0.349494   \n",
       "2   may         mon  ... -0.290186 -0.124520 -0.565922  0.195414 -0.349494   \n",
       "3   may         mon  ... -0.002309 -0.413787 -0.565922  0.195414 -0.349494   \n",
       "4   may         mon  ...  1.533034  0.187888 -0.565922  0.195414 -0.349494   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \n",
       "0      0.648092        0.722722       0.886447    0.71246      0.33168  \n",
       "1      0.648092        0.722722       0.886447    0.71246      0.33168  \n",
       "2      0.648092        0.722722       0.886447    0.71246      0.33168  \n",
       "3      0.648092        0.722722       0.886447    0.71246      0.33168  \n",
       "4      0.648092        0.722722       0.886447    0.71246      0.33168  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data = pd.concat([df[['job','marital','contact', 'poutcome','education', 'default', 'housing', 'loan', 'month',\n",
    "       'day_of_week','y']].reset_index(drop=True),\n",
    "                    pd.DataFrame(scaler.transform(df[feature_scale]), columns=feature_scale)],\n",
    "                    axis=1)\n",
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ed26e945",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         no\n",
       "1         no\n",
       "2         no\n",
       "3         no\n",
       "4         no\n",
       "        ... \n",
       "41183    yes\n",
       "41184     no\n",
       "41185     no\n",
       "41186    yes\n",
       "41187     no\n",
       "Name: y, Length: 41188, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c0e453dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ae05cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['marital'] = df['marital'].astype('category').cat.codes\n",
    "df['contact'] = df['contact'].astype('category').cat.codes\n",
    "df['poutcome'] = df['poutcome'].astype('category').cat.codes\n",
    "df['education'] = df['education'].astype('category').cat.codes\n",
    "df['default'] = df['default'].astype('category').cat.codes\n",
    "df['housing'] = df['housing'].astype('category').cat.codes\n",
    "df['loan'] = df['loan'].astype('category').cat.codes\n",
    "df['month'] = df['month'].astype('category').cat.codes\n",
    "df['day_of_week'] = df['day_of_week'].astype('category').cat.codes\n",
    "df['y'] = df['y'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "42ed4203",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  7,  0,  1,  9,  5,  4, 10,  6, 11,  2,  8], dtype=int8)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d9bac542",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_indices = list(range(df.shape[1]))\n",
    "col_indices.remove(df.columns.get_loc('y'))\n",
    "X = df.iloc[:, col_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7068d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[:, 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b122169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.iloc[:5000]\n",
    "y=y.iloc[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "388f544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e153d001",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3934426229508197"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "clf.fit(X=X_train, y=y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "f1_score(y_pred,y_test) # 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5e06c7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.963"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "431c754b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "36a28bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8f96db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.to_numpy()\n",
    "X_test=X_test.to_numpy()\n",
    "y_test=y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "498de03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=torch.tensor(X_train.astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f824e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=torch.tensor(X_test.astype(\"float32\"))\n",
    "y_train=torch.tensor(y_train.astype(\"float32\"))\n",
    "y_test=torch.tensor(y_test.astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f4136b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4=nntree_gen(20,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f246714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.BCELoss()\n",
    "optimizer=torch.optim.Adam(model4.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0ae12038",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.8670, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(8.5874, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(6.6823, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(5.1967, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(3.9710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(3.0930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(2.4137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.9051, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.5013, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.3008, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.1314, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(1.0302, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.9501, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.8135, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7372, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.7087, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6842, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6267, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.6113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5835, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5708, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5585, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5466, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5351, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5239, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.5016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4907, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4799, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4695, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4593, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4397, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4303, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.4042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3713, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3627, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3540, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3451, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3363, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3275, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3188, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.3015, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2857, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2728, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2669, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2612, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2556, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2500, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2333, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2281, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2232, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2183, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2137, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2053, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.2014, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1894, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1856, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1818, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1784, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1750, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1718, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1661, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1635, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1568, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1529, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1510, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1473, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1456, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1438, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1422, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1329, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.1310, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "num_epochs=100\n",
    "epoch=0\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    output=model4(X_train[:].T)\n",
    "    loss=criterion(output[:,0],y_train)\n",
    "    optimizer.zero_grad()\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "#     for name, param in mobdel4.named_parameters():\n",
    "#         if param.grad is not None:\n",
    "#             print(f'Gradient of parameter {name}:')\n",
    "#             print(param.grad)\n",
    "    optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "24a96bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "30f69775",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "y_pred1=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    k=0\n",
    "    if(model4(X_test[i].reshape((20,1)))[0][0]>0.5):\n",
    "        k=1\n",
    "    else:\n",
    "        k=0\n",
    "    \n",
    "    y_pred1.append(k)\n",
    "    if(k==y_test[i]):\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cff86ffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a12544ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41379310344827586"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred1,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d1765a7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3934426229508197"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "23cbf859",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if self.alpha is not None:\n",
    "            self.alpha = torch.Tensor(alpha)\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, probs, targets):\n",
    "        # Compute softmax probabilities\n",
    "    \n",
    "\n",
    "        # Compute binary cross entropy\n",
    "        bce_loss = nn.BCELoss(reduction='none')(probs, targets)\n",
    "\n",
    "        # Compute focal loss\n",
    "        focal_weights = (1 - probs) ** self.gamma\n",
    "        focal_loss = torch.where(targets == 1, focal_weights * bce_loss, (probs ** self.gamma) * bce_loss)\n",
    "\n",
    "        # Apply class weights if provided\n",
    "        if self.alpha is not None:\n",
    "            focal_loss = self.alpha[targets] * focal_loss\n",
    "\n",
    "        # Compute final loss based on reduction option\n",
    "        if self.reduction == 'mean':\n",
    "            focal_loss = torch.mean(focal_loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            focal_loss = torch.sum(focal_loss)\n",
    "\n",
    "        return focal_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2625f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4=nntree_gen(20,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "34c817d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=FocalLoss()\n",
    "optimizer=torch.optim.Adam(model4.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "74c441a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1147, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1139, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1131, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1124, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1116, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1108, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1100, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1093, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1085, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1077, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1069, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1060, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1052, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1045, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1037, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1030, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1022, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1014, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1006, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0998, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0991, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0983, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0976, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0968, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0961, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0954, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0947, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0940, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0933, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0926, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0919, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0911, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0905, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0898, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0892, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0886, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0880, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0874, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0868, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0863, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0858, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0853, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0848, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0843, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0839, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0834, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0830, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0825, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0821, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0817, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0812, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0808, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0804, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0800, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0792, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0789, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0785, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0782, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0778, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0775, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0771, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0768, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0765, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0762, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0759, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0757, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0754, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0751, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0749, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0746, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0744, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0742, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0740, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0735, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0733, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0730, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0728, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0724, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0722, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0719, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0717, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0715, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0713, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0709, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0707, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0705, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0704, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0702, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0700, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0698, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0697, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0695, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0694, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0692, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0690, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0689, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "num_epochs=100\n",
    "epoch=0\n",
    "for epoch in range(num_epochs):\n",
    "    output=model4(X_train[:].T)\n",
    "    loss=criterion(output[:,0],y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "#     for name, param in mobdel4.named_parameters():\n",
    "#         if param.grad is not None:\n",
    "#             print(f'Gradient of parameter {name}:')\n",
    "#             print(param.grad)\n",
    "    optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "c50aec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "y_pred1=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    k=0\n",
    "    if(model4(X_test[i].reshape((20,1)))[0][0]>0.5):\n",
    "        k=1\n",
    "    else:\n",
    "        k=0\n",
    "    \n",
    "    y_pred1.append(k)\n",
    "    if(k==y_test[i]):\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "cfbcc72a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8840738043214372"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d4433c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3696369636963696"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred1,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6de43f",
   "metadata": {},
   "source": [
    "#### Diabetes dataset(more attributes and not skewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "7b9ac0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "a03c470b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "45da4495",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "551d65dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop('id', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "62a780eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Unnamed: 32\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "8eee2dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Categorical_variables=[\"diagnosis\"]\n",
    "\n",
    "feature_scale=[feature for feature in df.columns if feature not in Categorical_variables]\n",
    "\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(df[feature_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "284a3939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>2.217515</td>\n",
       "      <td>...</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>...</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>0.939685</td>\n",
       "      <td>...</td>\n",
       "      <td>1.511870</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>2.867383</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281464</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>-0.009560</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298575</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M     1.097064     -2.073335        1.269934   0.984375   \n",
       "1         M     1.829821     -0.353632        1.685955   1.908708   \n",
       "2         M     1.579888      0.456187        1.566503   1.558884   \n",
       "3         M    -0.768909      0.253732       -0.592687  -0.764464   \n",
       "4         M     1.750297     -1.151816        1.776573   1.826229   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0         1.568466          3.283515        2.652874             2.532475   \n",
       "1        -0.826962         -0.487072       -0.023846             0.548144   \n",
       "2         0.942210          1.052926        1.363478             2.037231   \n",
       "3         3.283553          3.402909        1.915897             1.451707   \n",
       "4         0.280372          0.539340        1.371011             1.428493   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0       2.217515  ...      1.886690      -1.359293         2.303601   \n",
       "1       0.001392  ...      1.805927      -0.369203         1.535126   \n",
       "2       0.939685  ...      1.511870      -0.023974         1.347475   \n",
       "3       2.867383  ...     -0.281464       0.133984        -0.249939   \n",
       "4      -0.009560  ...      1.298575      -1.466770         1.338539   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0    2.001237          1.307686           2.616665         2.109526   \n",
       "1    1.890489         -0.375612          -0.430444        -0.146749   \n",
       "2    1.456285          0.527407           1.082932         0.854974   \n",
       "3   -0.550021          3.394275           3.893397         1.989588   \n",
       "4    1.220724          0.220556          -0.313395         0.613179   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0              2.296076        2.750622                 1.937015  \n",
       "1              1.087084       -0.243890                 0.281190  \n",
       "2              1.955000        1.152255                 0.201391  \n",
       "3              2.175786        6.046041                 4.935010  \n",
       "4              0.729259       -0.868353                -0.397100  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data = pd.concat([df[['diagnosis']].reset_index(drop=True),\n",
    "                    pd.DataFrame(scaler.transform(df[feature_scale]), columns=feature_scale)],\n",
    "                    axis=1)\n",
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "3b596312",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "3fc932cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'] = df['diagnosis'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "ac40211f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>2.217515</td>\n",
       "      <td>...</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>...</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>0.939685</td>\n",
       "      <td>...</td>\n",
       "      <td>1.511870</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>2.867383</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281464</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>-0.009560</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298575</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>1</td>\n",
       "      <td>2.110995</td>\n",
       "      <td>0.721473</td>\n",
       "      <td>2.060786</td>\n",
       "      <td>2.343856</td>\n",
       "      <td>1.041842</td>\n",
       "      <td>0.219060</td>\n",
       "      <td>1.947285</td>\n",
       "      <td>2.320965</td>\n",
       "      <td>-0.312589</td>\n",
       "      <td>...</td>\n",
       "      <td>1.901185</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>1.752563</td>\n",
       "      <td>2.015301</td>\n",
       "      <td>0.378365</td>\n",
       "      <td>-0.273318</td>\n",
       "      <td>0.664512</td>\n",
       "      <td>1.629151</td>\n",
       "      <td>-1.360158</td>\n",
       "      <td>-0.709091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1</td>\n",
       "      <td>1.704854</td>\n",
       "      <td>2.085134</td>\n",
       "      <td>1.615931</td>\n",
       "      <td>1.723842</td>\n",
       "      <td>0.102458</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>0.693043</td>\n",
       "      <td>1.263669</td>\n",
       "      <td>-0.217664</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536720</td>\n",
       "      <td>2.047399</td>\n",
       "      <td>1.421940</td>\n",
       "      <td>1.494959</td>\n",
       "      <td>-0.691230</td>\n",
       "      <td>-0.394820</td>\n",
       "      <td>0.236573</td>\n",
       "      <td>0.733827</td>\n",
       "      <td>-0.531855</td>\n",
       "      <td>-0.973978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1</td>\n",
       "      <td>0.702284</td>\n",
       "      <td>2.045574</td>\n",
       "      <td>0.672676</td>\n",
       "      <td>0.577953</td>\n",
       "      <td>-0.840484</td>\n",
       "      <td>-0.038680</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>0.105777</td>\n",
       "      <td>-0.809117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561361</td>\n",
       "      <td>1.374854</td>\n",
       "      <td>0.579001</td>\n",
       "      <td>0.427906</td>\n",
       "      <td>-0.809587</td>\n",
       "      <td>0.350735</td>\n",
       "      <td>0.326767</td>\n",
       "      <td>0.414069</td>\n",
       "      <td>-1.104549</td>\n",
       "      <td>-0.318409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1</td>\n",
       "      <td>1.838341</td>\n",
       "      <td>2.336457</td>\n",
       "      <td>1.982524</td>\n",
       "      <td>1.735218</td>\n",
       "      <td>1.525767</td>\n",
       "      <td>3.272144</td>\n",
       "      <td>3.296944</td>\n",
       "      <td>2.658866</td>\n",
       "      <td>2.137194</td>\n",
       "      <td>...</td>\n",
       "      <td>1.961239</td>\n",
       "      <td>2.237926</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>1.653171</td>\n",
       "      <td>1.430427</td>\n",
       "      <td>3.904848</td>\n",
       "      <td>3.197605</td>\n",
       "      <td>2.289985</td>\n",
       "      <td>1.919083</td>\n",
       "      <td>2.219635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.808401</td>\n",
       "      <td>1.221792</td>\n",
       "      <td>-1.814389</td>\n",
       "      <td>-1.347789</td>\n",
       "      <td>-3.112085</td>\n",
       "      <td>-1.150752</td>\n",
       "      <td>-1.114873</td>\n",
       "      <td>-1.261820</td>\n",
       "      <td>-0.820070</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.410893</td>\n",
       "      <td>0.764190</td>\n",
       "      <td>-1.432735</td>\n",
       "      <td>-1.075813</td>\n",
       "      <td>-1.859019</td>\n",
       "      <td>-1.207552</td>\n",
       "      <td>-1.305831</td>\n",
       "      <td>-1.745063</td>\n",
       "      <td>-0.048138</td>\n",
       "      <td>-0.751207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0            1     1.097064     -2.073335        1.269934   0.984375   \n",
       "1            1     1.829821     -0.353632        1.685955   1.908708   \n",
       "2            1     1.579888      0.456187        1.566503   1.558884   \n",
       "3            1    -0.768909      0.253732       -0.592687  -0.764464   \n",
       "4            1     1.750297     -1.151816        1.776573   1.826229   \n",
       "..         ...          ...           ...             ...        ...   \n",
       "564          1     2.110995      0.721473        2.060786   2.343856   \n",
       "565          1     1.704854      2.085134        1.615931   1.723842   \n",
       "566          1     0.702284      2.045574        0.672676   0.577953   \n",
       "567          1     1.838341      2.336457        1.982524   1.735218   \n",
       "568          0    -1.808401      1.221792       -1.814389  -1.347789   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0           1.568466          3.283515        2.652874             2.532475   \n",
       "1          -0.826962         -0.487072       -0.023846             0.548144   \n",
       "2           0.942210          1.052926        1.363478             2.037231   \n",
       "3           3.283553          3.402909        1.915897             1.451707   \n",
       "4           0.280372          0.539340        1.371011             1.428493   \n",
       "..               ...               ...             ...                  ...   \n",
       "564         1.041842          0.219060        1.947285             2.320965   \n",
       "565         0.102458         -0.017833        0.693043             1.263669   \n",
       "566        -0.840484         -0.038680        0.046588             0.105777   \n",
       "567         1.525767          3.272144        3.296944             2.658866   \n",
       "568        -3.112085         -1.150752       -1.114873            -1.261820   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         2.217515  ...      1.886690      -1.359293         2.303601   \n",
       "1         0.001392  ...      1.805927      -0.369203         1.535126   \n",
       "2         0.939685  ...      1.511870      -0.023974         1.347475   \n",
       "3         2.867383  ...     -0.281464       0.133984        -0.249939   \n",
       "4        -0.009560  ...      1.298575      -1.466770         1.338539   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564      -0.312589  ...      1.901185       0.117700         1.752563   \n",
       "565      -0.217664  ...      1.536720       2.047399         1.421940   \n",
       "566      -0.809117  ...      0.561361       1.374854         0.579001   \n",
       "567       2.137194  ...      1.961239       2.237926         2.303601   \n",
       "568      -0.820070  ...     -1.410893       0.764190        -1.432735   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2.001237          1.307686           2.616665         2.109526   \n",
       "1      1.890489         -0.375612          -0.430444        -0.146749   \n",
       "2      1.456285          0.527407           1.082932         0.854974   \n",
       "3     -0.550021          3.394275           3.893397         1.989588   \n",
       "4      1.220724          0.220556          -0.313395         0.613179   \n",
       "..          ...               ...                ...              ...   \n",
       "564    2.015301          0.378365          -0.273318         0.664512   \n",
       "565    1.494959         -0.691230          -0.394820         0.236573   \n",
       "566    0.427906         -0.809587           0.350735         0.326767   \n",
       "567    1.653171          1.430427           3.904848         3.197605   \n",
       "568   -1.075813         -1.859019          -1.207552        -1.305831   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                2.296076        2.750622                 1.937015  \n",
       "1                1.087084       -0.243890                 0.281190  \n",
       "2                1.955000        1.152255                 0.201391  \n",
       "3                2.175786        6.046041                 4.935010  \n",
       "4                0.729259       -0.868353                -0.397100  \n",
       "..                    ...             ...                      ...  \n",
       "564              1.629151       -1.360158                -0.709091  \n",
       "565              0.733827       -0.531855                -0.973978  \n",
       "566              0.414069       -1.104549                -0.318409  \n",
       "567              2.289985        1.919083                 2.219635  \n",
       "568             -1.745063       -0.048138                -0.751207  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "5968984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[\"diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "ab1508a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('diagnosis', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "0c8d430e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "clf.fit(X=X_train, y=y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "56526f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "c64a872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.to_numpy()\n",
    "y_train=y_train.to_numpy()\n",
    "X_test=X_test.to_numpy()\n",
    "y_test=y_test.to_numpy()\n",
    "X_train=torch.tensor(X_train.astype(\"float32\"))\n",
    "X_test=torch.tensor(X_test.astype(\"float32\"))\n",
    "y_train=torch.tensor(y_train.astype(\"float32\"))\n",
    "y_test=torch.tensor(y_test.astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "5493ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4=nntree_gen(30,5)\n",
    "criterion=FocalLoss()\n",
    "optimizer=torch.optim.Adam(model4.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "66317148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4350, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1524, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0689, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0327, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0033, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9768, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7655, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7381, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7106, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6851, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6625, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6433, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6276, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6184, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6115, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6052, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5996, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5945, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5899, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5855, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5816, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5780, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5748, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5719, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5691, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5667, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5647, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3781, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3649, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3483, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3392, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3385, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3381, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3374, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3362, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3343, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3324, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3307, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3295, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3285, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3276, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3267, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3258, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3250, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3241, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3231, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3221, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3212, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3204, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3195, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3187, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3178, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3170, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3162, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3154, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1299, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1291, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1242, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1188, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1130, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1070, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1008, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0941, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0897, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0887, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0880, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0872, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0864, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0855, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0847, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0839, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0831, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0824, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0817, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0810, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0804, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0797, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0791, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0785, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0778, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0772, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0766, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0760, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0754, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0748, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0743, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0737, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0732, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0726, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0721, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0716, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0706, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0701, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0696, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0692, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0687, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0683, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0678, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0674, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "num_epochs=100\n",
    "epoch=0\n",
    "for epoch in range(num_epochs):\n",
    "    output=model4(X_train[:].T)\n",
    "    loss=criterion(output[:,0],y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "#     for name, param in mobdel4.named_parameters():\n",
    "#         if param.grad is not None:\n",
    "#             print(f'Gradient of parameter {name}:')\n",
    "#             print(param.grad)\n",
    "    optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "dd66ea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "y_pred1=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    k=0\n",
    "    if(model4(X_test[i].reshape((30,1)))[0][0]>0.5):\n",
    "        k=1\n",
    "    else:\n",
    "        k=0\n",
    "    \n",
    "    y_pred1.append(k)\n",
    "    if(k==y_test[i]):\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7b0d5b",
   "metadata": {},
   "source": [
    "# Madelon Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "7ef8bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"madelon_train.data\",delimiter=' ', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "02885f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>485</td>\n",
       "      <td>477</td>\n",
       "      <td>537</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>471</td>\n",
       "      <td>491</td>\n",
       "      <td>476</td>\n",
       "      <td>475</td>\n",
       "      <td>473</td>\n",
       "      <td>...</td>\n",
       "      <td>481</td>\n",
       "      <td>477</td>\n",
       "      <td>485</td>\n",
       "      <td>511</td>\n",
       "      <td>485</td>\n",
       "      <td>481</td>\n",
       "      <td>479</td>\n",
       "      <td>475</td>\n",
       "      <td>496</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>483</td>\n",
       "      <td>458</td>\n",
       "      <td>460</td>\n",
       "      <td>487</td>\n",
       "      <td>587</td>\n",
       "      <td>475</td>\n",
       "      <td>526</td>\n",
       "      <td>479</td>\n",
       "      <td>485</td>\n",
       "      <td>469</td>\n",
       "      <td>...</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>338</td>\n",
       "      <td>513</td>\n",
       "      <td>486</td>\n",
       "      <td>483</td>\n",
       "      <td>492</td>\n",
       "      <td>510</td>\n",
       "      <td>517</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>487</td>\n",
       "      <td>542</td>\n",
       "      <td>499</td>\n",
       "      <td>468</td>\n",
       "      <td>448</td>\n",
       "      <td>471</td>\n",
       "      <td>442</td>\n",
       "      <td>478</td>\n",
       "      <td>480</td>\n",
       "      <td>477</td>\n",
       "      <td>...</td>\n",
       "      <td>481</td>\n",
       "      <td>492</td>\n",
       "      <td>650</td>\n",
       "      <td>506</td>\n",
       "      <td>501</td>\n",
       "      <td>480</td>\n",
       "      <td>489</td>\n",
       "      <td>499</td>\n",
       "      <td>498</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>480</td>\n",
       "      <td>491</td>\n",
       "      <td>510</td>\n",
       "      <td>485</td>\n",
       "      <td>495</td>\n",
       "      <td>472</td>\n",
       "      <td>417</td>\n",
       "      <td>474</td>\n",
       "      <td>502</td>\n",
       "      <td>476</td>\n",
       "      <td>...</td>\n",
       "      <td>480</td>\n",
       "      <td>474</td>\n",
       "      <td>572</td>\n",
       "      <td>454</td>\n",
       "      <td>469</td>\n",
       "      <td>475</td>\n",
       "      <td>482</td>\n",
       "      <td>494</td>\n",
       "      <td>461</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>484</td>\n",
       "      <td>502</td>\n",
       "      <td>528</td>\n",
       "      <td>489</td>\n",
       "      <td>466</td>\n",
       "      <td>481</td>\n",
       "      <td>402</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>468</td>\n",
       "      <td>...</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>435</td>\n",
       "      <td>486</td>\n",
       "      <td>508</td>\n",
       "      <td>481</td>\n",
       "      <td>504</td>\n",
       "      <td>495</td>\n",
       "      <td>511</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>490</td>\n",
       "      <td>505</td>\n",
       "      <td>503</td>\n",
       "      <td>474</td>\n",
       "      <td>463</td>\n",
       "      <td>461</td>\n",
       "      <td>519</td>\n",
       "      <td>476</td>\n",
       "      <td>518</td>\n",
       "      <td>467</td>\n",
       "      <td>...</td>\n",
       "      <td>479</td>\n",
       "      <td>449</td>\n",
       "      <td>588</td>\n",
       "      <td>499</td>\n",
       "      <td>506</td>\n",
       "      <td>475</td>\n",
       "      <td>463</td>\n",
       "      <td>507</td>\n",
       "      <td>501</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>480</td>\n",
       "      <td>475</td>\n",
       "      <td>476</td>\n",
       "      <td>480</td>\n",
       "      <td>495</td>\n",
       "      <td>482</td>\n",
       "      <td>515</td>\n",
       "      <td>479</td>\n",
       "      <td>480</td>\n",
       "      <td>484</td>\n",
       "      <td>...</td>\n",
       "      <td>474</td>\n",
       "      <td>473</td>\n",
       "      <td>424</td>\n",
       "      <td>454</td>\n",
       "      <td>570</td>\n",
       "      <td>476</td>\n",
       "      <td>493</td>\n",
       "      <td>465</td>\n",
       "      <td>485</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>480</td>\n",
       "      <td>517</td>\n",
       "      <td>631</td>\n",
       "      <td>470</td>\n",
       "      <td>485</td>\n",
       "      <td>474</td>\n",
       "      <td>535</td>\n",
       "      <td>476</td>\n",
       "      <td>493</td>\n",
       "      <td>466</td>\n",
       "      <td>...</td>\n",
       "      <td>483</td>\n",
       "      <td>479</td>\n",
       "      <td>687</td>\n",
       "      <td>488</td>\n",
       "      <td>488</td>\n",
       "      <td>483</td>\n",
       "      <td>500</td>\n",
       "      <td>523</td>\n",
       "      <td>481</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>484</td>\n",
       "      <td>481</td>\n",
       "      <td>505</td>\n",
       "      <td>478</td>\n",
       "      <td>542</td>\n",
       "      <td>477</td>\n",
       "      <td>518</td>\n",
       "      <td>477</td>\n",
       "      <td>510</td>\n",
       "      <td>472</td>\n",
       "      <td>...</td>\n",
       "      <td>483</td>\n",
       "      <td>526</td>\n",
       "      <td>750</td>\n",
       "      <td>486</td>\n",
       "      <td>529</td>\n",
       "      <td>484</td>\n",
       "      <td>473</td>\n",
       "      <td>527</td>\n",
       "      <td>485</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>474</td>\n",
       "      <td>493</td>\n",
       "      <td>469</td>\n",
       "      <td>486</td>\n",
       "      <td>521</td>\n",
       "      <td>475</td>\n",
       "      <td>494</td>\n",
       "      <td>479</td>\n",
       "      <td>481</td>\n",
       "      <td>473</td>\n",
       "      <td>...</td>\n",
       "      <td>476</td>\n",
       "      <td>508</td>\n",
       "      <td>449</td>\n",
       "      <td>463</td>\n",
       "      <td>533</td>\n",
       "      <td>481</td>\n",
       "      <td>489</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    ...  491  492  493  \\\n",
       "0     485  477  537  479  452  471  491  476  475  473  ...  481  477  485   \n",
       "1     483  458  460  487  587  475  526  479  485  469  ...  478  487  338   \n",
       "2     487  542  499  468  448  471  442  478  480  477  ...  481  492  650   \n",
       "3     480  491  510  485  495  472  417  474  502  476  ...  480  474  572   \n",
       "4     484  502  528  489  466  481  402  478  487  468  ...  479  452  435   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1995  490  505  503  474  463  461  519  476  518  467  ...  479  449  588   \n",
       "1996  480  475  476  480  495  482  515  479  480  484  ...  474  473  424   \n",
       "1997  480  517  631  470  485  474  535  476  493  466  ...  483  479  687   \n",
       "1998  484  481  505  478  542  477  518  477  510  472  ...  483  526  750   \n",
       "1999  474  493  469  486  521  475  494  479  481  473  ...  476  508  449   \n",
       "\n",
       "      494  495  496  497  498  499  500  \n",
       "0     511  485  481  479  475  496  NaN  \n",
       "1     513  486  483  492  510  517  NaN  \n",
       "2     506  501  480  489  499  498  NaN  \n",
       "3     454  469  475  482  494  461  NaN  \n",
       "4     486  508  481  504  495  511  NaN  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "1995  499  506  475  463  507  501  NaN  \n",
       "1996  454  570  476  493  465  485  NaN  \n",
       "1997  488  488  483  500  523  481  NaN  \n",
       "1998  486  529  484  473  527  485  NaN  \n",
       "1999  463  533  481  489  516  516  NaN  \n",
       "\n",
       "[2000 rows x 501 columns]"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "12c34c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels= pd.read_csv(\"madelon_train.labels\",delimiter=' ', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "c5e99282",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop(500,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "eec0da1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      485\n",
       "1      477\n",
       "2      537\n",
       "3      479\n",
       "4      452\n",
       "      ... \n",
       "495    485\n",
       "496    481\n",
       "497    479\n",
       "498    475\n",
       "499    496\n",
       "Name: 0, Length: 500, dtype: int64"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "a37a45ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_scale=[feature for feature in train.columns]\n",
    "\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(train[feature_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "d73b5902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>485</td>\n",
       "      <td>477</td>\n",
       "      <td>537</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>471</td>\n",
       "      <td>491</td>\n",
       "      <td>476</td>\n",
       "      <td>475</td>\n",
       "      <td>473</td>\n",
       "      <td>...</td>\n",
       "      <td>477</td>\n",
       "      <td>481</td>\n",
       "      <td>477</td>\n",
       "      <td>485</td>\n",
       "      <td>511</td>\n",
       "      <td>485</td>\n",
       "      <td>481</td>\n",
       "      <td>479</td>\n",
       "      <td>475</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>483</td>\n",
       "      <td>458</td>\n",
       "      <td>460</td>\n",
       "      <td>487</td>\n",
       "      <td>587</td>\n",
       "      <td>475</td>\n",
       "      <td>526</td>\n",
       "      <td>479</td>\n",
       "      <td>485</td>\n",
       "      <td>469</td>\n",
       "      <td>...</td>\n",
       "      <td>463</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>338</td>\n",
       "      <td>513</td>\n",
       "      <td>486</td>\n",
       "      <td>483</td>\n",
       "      <td>492</td>\n",
       "      <td>510</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>487</td>\n",
       "      <td>542</td>\n",
       "      <td>499</td>\n",
       "      <td>468</td>\n",
       "      <td>448</td>\n",
       "      <td>471</td>\n",
       "      <td>442</td>\n",
       "      <td>478</td>\n",
       "      <td>480</td>\n",
       "      <td>477</td>\n",
       "      <td>...</td>\n",
       "      <td>487</td>\n",
       "      <td>481</td>\n",
       "      <td>492</td>\n",
       "      <td>650</td>\n",
       "      <td>506</td>\n",
       "      <td>501</td>\n",
       "      <td>480</td>\n",
       "      <td>489</td>\n",
       "      <td>499</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>480</td>\n",
       "      <td>491</td>\n",
       "      <td>510</td>\n",
       "      <td>485</td>\n",
       "      <td>495</td>\n",
       "      <td>472</td>\n",
       "      <td>417</td>\n",
       "      <td>474</td>\n",
       "      <td>502</td>\n",
       "      <td>476</td>\n",
       "      <td>...</td>\n",
       "      <td>491</td>\n",
       "      <td>480</td>\n",
       "      <td>474</td>\n",
       "      <td>572</td>\n",
       "      <td>454</td>\n",
       "      <td>469</td>\n",
       "      <td>475</td>\n",
       "      <td>482</td>\n",
       "      <td>494</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>484</td>\n",
       "      <td>502</td>\n",
       "      <td>528</td>\n",
       "      <td>489</td>\n",
       "      <td>466</td>\n",
       "      <td>481</td>\n",
       "      <td>402</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>468</td>\n",
       "      <td>...</td>\n",
       "      <td>488</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>435</td>\n",
       "      <td>486</td>\n",
       "      <td>508</td>\n",
       "      <td>481</td>\n",
       "      <td>504</td>\n",
       "      <td>495</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>490</td>\n",
       "      <td>505</td>\n",
       "      <td>503</td>\n",
       "      <td>474</td>\n",
       "      <td>463</td>\n",
       "      <td>461</td>\n",
       "      <td>519</td>\n",
       "      <td>476</td>\n",
       "      <td>518</td>\n",
       "      <td>467</td>\n",
       "      <td>...</td>\n",
       "      <td>467</td>\n",
       "      <td>479</td>\n",
       "      <td>449</td>\n",
       "      <td>588</td>\n",
       "      <td>499</td>\n",
       "      <td>506</td>\n",
       "      <td>475</td>\n",
       "      <td>463</td>\n",
       "      <td>507</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>480</td>\n",
       "      <td>475</td>\n",
       "      <td>476</td>\n",
       "      <td>480</td>\n",
       "      <td>495</td>\n",
       "      <td>482</td>\n",
       "      <td>515</td>\n",
       "      <td>479</td>\n",
       "      <td>480</td>\n",
       "      <td>484</td>\n",
       "      <td>...</td>\n",
       "      <td>464</td>\n",
       "      <td>474</td>\n",
       "      <td>473</td>\n",
       "      <td>424</td>\n",
       "      <td>454</td>\n",
       "      <td>570</td>\n",
       "      <td>476</td>\n",
       "      <td>493</td>\n",
       "      <td>465</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>480</td>\n",
       "      <td>517</td>\n",
       "      <td>631</td>\n",
       "      <td>470</td>\n",
       "      <td>485</td>\n",
       "      <td>474</td>\n",
       "      <td>535</td>\n",
       "      <td>476</td>\n",
       "      <td>493</td>\n",
       "      <td>466</td>\n",
       "      <td>...</td>\n",
       "      <td>501</td>\n",
       "      <td>483</td>\n",
       "      <td>479</td>\n",
       "      <td>687</td>\n",
       "      <td>488</td>\n",
       "      <td>488</td>\n",
       "      <td>483</td>\n",
       "      <td>500</td>\n",
       "      <td>523</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>484</td>\n",
       "      <td>481</td>\n",
       "      <td>505</td>\n",
       "      <td>478</td>\n",
       "      <td>542</td>\n",
       "      <td>477</td>\n",
       "      <td>518</td>\n",
       "      <td>477</td>\n",
       "      <td>510</td>\n",
       "      <td>472</td>\n",
       "      <td>...</td>\n",
       "      <td>487</td>\n",
       "      <td>483</td>\n",
       "      <td>526</td>\n",
       "      <td>750</td>\n",
       "      <td>486</td>\n",
       "      <td>529</td>\n",
       "      <td>484</td>\n",
       "      <td>473</td>\n",
       "      <td>527</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>474</td>\n",
       "      <td>493</td>\n",
       "      <td>469</td>\n",
       "      <td>486</td>\n",
       "      <td>521</td>\n",
       "      <td>475</td>\n",
       "      <td>494</td>\n",
       "      <td>479</td>\n",
       "      <td>481</td>\n",
       "      <td>473</td>\n",
       "      <td>...</td>\n",
       "      <td>467</td>\n",
       "      <td>476</td>\n",
       "      <td>508</td>\n",
       "      <td>449</td>\n",
       "      <td>463</td>\n",
       "      <td>533</td>\n",
       "      <td>481</td>\n",
       "      <td>489</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       "0     485  477  537  479  452  471  491  476  475  473  ...  477  481  477   \n",
       "1     483  458  460  487  587  475  526  479  485  469  ...  463  478  487   \n",
       "2     487  542  499  468  448  471  442  478  480  477  ...  487  481  492   \n",
       "3     480  491  510  485  495  472  417  474  502  476  ...  491  480  474   \n",
       "4     484  502  528  489  466  481  402  478  487  468  ...  488  479  452   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1995  490  505  503  474  463  461  519  476  518  467  ...  467  479  449   \n",
       "1996  480  475  476  480  495  482  515  479  480  484  ...  464  474  473   \n",
       "1997  480  517  631  470  485  474  535  476  493  466  ...  501  483  479   \n",
       "1998  484  481  505  478  542  477  518  477  510  472  ...  487  483  526   \n",
       "1999  474  493  469  486  521  475  494  479  481  473  ...  467  476  508   \n",
       "\n",
       "      493  494  495  496  497  498  499  \n",
       "0     485  511  485  481  479  475  496  \n",
       "1     338  513  486  483  492  510  517  \n",
       "2     650  506  501  480  489  499  498  \n",
       "3     572  454  469  475  482  494  461  \n",
       "4     435  486  508  481  504  495  511  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  \n",
       "1995  588  499  506  475  463  507  501  \n",
       "1996  424  454  570  476  493  465  485  \n",
       "1997  687  488  488  483  500  523  481  \n",
       "1998  750  486  529  484  473  527  485  \n",
       "1999  449  463  533  481  489  516  516  \n",
       "\n",
       "[2000 rows x 500 columns]"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[feature_scale]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "b7973271",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scaled_data = pd.DataFrame(scaler.transform(train[feature_scale]), columns=feature_scale)\n",
    "train=scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "dcb0626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "2f8e3113",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[0] = train_labels[0].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "a1ae3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "46462590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.755"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "clf.fit(X=X_train, y=y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "8e0382ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.to_numpy()\n",
    "y_train=y_train.to_numpy()\n",
    "X_test=X_test.to_numpy()\n",
    "y_test=y_test.to_numpy()\n",
    "X_train=torch.tensor(X_train.astype(\"float32\"))\n",
    "X_test=torch.tensor(X_test.astype(\"float32\"))\n",
    "y_train=torch.tensor(y_train.astype(\"float32\"))\n",
    "y_test=torch.tensor(y_test.astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "2e4a4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.reshape(y_train.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "466777fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4=nntree_gen(500,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "5d69273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.BCELoss()\n",
    "optimizer=torch.optim.Adam(model4.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "d72d5f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(26.0833, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(26.0699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(26.0906, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(26.1213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(26.0699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(26.0748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(26.0394, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(25.9285, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(25.9240, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17308\\2341651097.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17308\\1057889585.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0mcurr1_o\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                     \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_o\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m                     \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                     \u001b[0mcurr1_o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs=100\n",
    "epoch=0\n",
    "for epoch in range(num_epochs):\n",
    "    output=model4(X_train.T)\n",
    "    loss=criterion(output[:,0],y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "#     for name, param in model4.named_parameters():\n",
    "#         if param.grad is not None:\n",
    "#             print(f'Gradient of parameter {name}:')\n",
    "#             print(param.grad)\n",
    "    optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "50f69f39",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17308\\345497497.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17308\\1057889585.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                     \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_o\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                     \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                     \u001b[0mcurr1_o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                     \u001b[0mcurr1_o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count=0\n",
    "y_pred1=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    k=0\n",
    "    if(model4(X_test[i].reshape((500,1)))[0][0]>0.5):\n",
    "        k=1\n",
    "    else:\n",
    "        k=0\n",
    "    \n",
    "    y_pred1.append(k)\n",
    "    if(k==y_test[i]):\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "5426ad52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4625"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "e0cdf604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.3246e-38, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[2.3779e-24, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.7075, 0.2925]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[5.9630e-28, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3925, 0.6075]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.1256, 0.8744]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 3.4245e-06]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.4073e-28, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 3.6658e-26]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.7653, 0.2347]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[2.5385e-17, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.2610, 0.7390]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 6.2022e-10]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4911, 0.5089]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.0294, 0.9706]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.6576, 0.3424]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[8.0699e-07, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[9.9997e-01, 2.9465e-05]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.9941, 0.0059]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 2.7697e-06]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.1197, 0.8803]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.9858, 0.0142]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[2.6903e-35, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.1585e-11, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.8596, 0.1404]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 1.4854e-30]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.8239, 0.1761]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[5.1592e-24, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.9925, 0.0075]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.9899, 0.0101]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[3.9731e-37, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[9.9916e-01, 8.4149e-04]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.9954, 0.0046]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5325, 0.4675]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[3.6496e-08, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.0022, 0.9978]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[9.9999e-01, 5.7300e-06]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.0209, 0.9791]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 4.1713e-25]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.0085, 0.9915]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[2.4267e-17, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[8.6315e-12, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 4.0904e-38]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.2881, 0.7119]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[8.1546e-12, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[2.3500e-09, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 7.1758e-37]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.4169, 0.5831]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[3.4896e-17, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.8704, 0.1296]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 1.8637e-43]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.3175, 0.6825]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.7220, 0.2780]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 5.8552e-08]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.0361, 0.9639]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.1064, 0.8936]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.4580e-12, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.0017, 0.9983]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 1.1022e-19]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.0497, 0.9503]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 3.9380e-35]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[7.8917e-12, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 1.4769e-36]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[5.9066e-38, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[6.3928e-14, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 3.5422e-32]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.1180, 0.8820]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 5.2861e-07]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[5.0302e-23, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[6.2302e-42, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.3674, 0.6326]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[3.6851e-25, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 1.2777e-19]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 1.9068e-33]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 1.3033e-06]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[5.9173e-10, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 1.6585e-32]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 1.1151e-09]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[8.9185e-26, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.6934, 0.3066]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[7.3619e-11, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[9.9387e-31, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 5.2088e-12]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 3.8781e-09]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4750, 0.5250]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5214, 0.4786]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 6.5831e-11]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.0013, 0.9987]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.0382, 0.9618]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 1.9069e-13]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 1.0999e-13]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 3.2549e-14]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.9827, 0.0173]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[9.9952e-01, 4.8062e-04]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 1.0495e-07]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[2.5753e-06, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5227, 0.4773]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 2.3207e-07]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 2.6042e-33]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.4979e-13, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 7.2794e-35]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[6.1602e-04, 9.9938e-01]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.0021, 0.9979]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.0136, 0.9864]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 6.1809e-15]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 1.4447e-15]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[9.9934e-01, 6.6407e-04]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.9672, 0.0328]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.7574e-11, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2013, 0.7987]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.6536, 0.3464]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 3.6201e-26]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 1.6388e-25]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.6774, 0.3226]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 4.0594e-24]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.9077e-12, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 3.5735e-07]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 1.5588e-09]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.7447e-05, 9.9998e-01]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 5.7196e-15]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.7378e-06, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[2.5899e-06, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[6.7613e-42, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[5.0719e-08, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.0193, 0.9807]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 4.1879e-33]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4038, 0.5962]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 1.4782e-07]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 3.1389e-19]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.3885, 0.6115]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.6625, 0.3375]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 6.8532e-19]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[9.9999e-01, 5.0540e-06]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.7191, 0.2809]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 2.0405e-31]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.1160e-11, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[3.2643e-17, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.0056, 0.9944]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 1.7708e-07]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.0161, 0.9839]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 2.6448e-22]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.7616e-19, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2673, 0.7327]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.1402, 0.8598]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[2.3179e-29, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.4412, 0.5588]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.9956, 0.0044]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.8225, 0.1775]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 1.1099e-18]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.0081, 0.9919]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.4971e-11, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[4.4904e-25, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.7105, 0.2895]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.8679, 0.1321]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[5.9857e-12, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 2.1430e-09]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[2.2242e-05, 9.9998e-01]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[9.9999e-01, 1.2626e-05]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 6.8290e-18]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.9945, 0.0055]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4799, 0.5201]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 7.0065e-45]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.3591, 0.6409]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[5.2567e-05, 9.9995e-01]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 2.8357e-21]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.9926, 0.0074]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.9836, 0.0164]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[8.3341e-23, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.2131, 0.7869]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 2.1669e-21]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[4.8729e-32, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.5126, 0.4874]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[3.7186e-11, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 3.9999e-10]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.8370, 0.1630]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[4.1663e-08, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[3.3615e-05, 9.9997e-01]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[2.0552e-20, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 1.6030e-17]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 1.5310e-13]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 2.8339e-38]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.4900, 0.5100]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[8.9038e-07, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.7694, 0.2306]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 3.5060e-07]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0.0799, 0.9201]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.9736e-16, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0.0806, 0.9194]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1.0000e+00, 3.3139e-07]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.2925e-04, 9.9987e-01]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 8.8459e-07]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[2.7358e-32, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[9.9925e-01, 7.4533e-04]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 8.1036e-40]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[1.0000e+00, 1.2132e-19]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([1.])\n",
      "tensor([[2.8026e-44, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[2.6095e-04, 9.9974e-01]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[0., 1.]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n",
      "tensor([[8.8636e-25, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "y_pred1=[]\n",
    "for i in range(X_test.shape[0]):\n",
    "    print(model4(X_test[i].reshape((500,1))))\n",
    "    print(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac08a19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
